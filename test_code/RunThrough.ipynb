{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 906712\n",
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D : - awww , that 's a bummer . you shoulda got david carr of third day to do it . ; d \n",
      "\n",
      "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah! : is upset that he ca n't updat hi facebook by text it ... and might cri as a result school today also . blah ! \n",
      "\n",
      "@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds : i dive mani time for the ball . manag to save 50 % the rest go out of bound \n",
      "\n",
      "my whole body feels itchy and like its on fire  : my whole bodi feel itchi and like it on fire \n",
      "\n",
      "@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.  : no , it 's not behav at all . i 'm mad . whi am i here ? becaus i ca n't see you all over there . \n",
      "\n",
      "@Kwesidei not the whole crew  : not the whole crew \n",
      "\n",
      "Need a hug  : need a hug \n",
      "\n",
      "@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ? : hey long time no see ! yes.. rain a bit , onli a bit lol , i 'm fine thank , how 's you ? \n",
      "\n",
      "@Tatiana_K nope they didn't have it  : nope they did n't have it \n",
      "\n",
      "@twittera que me muera ?  : que me muera ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def removeTwitterData(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'^@\\S+','', tweet)\n",
    "    tweet = re.sub(r'https?\\S+','', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "def stemWords(tweet):\n",
    "    tokenizedTweet = word_tokenize(tweet)\n",
    "    stemmedWords = list(map(ps.stem, tokenizedTweet))\n",
    "    tweetAsString = \" \".join(str(word) for word in stemmedWords)\n",
    "    return tweetAsString\n",
    "\n",
    "def dataClean(tweet):\n",
    "    tweet = removeTwitterData(tweet)\n",
    "    tweet = stemWords(tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "with open('twitterDataset.csv', newline='') as csvfile:\n",
    "    tweetReader = csv.reader(csvfile)\n",
    "    listOfTweets = (list(tweetReader))\n",
    "    print(\"Size of dataset: {0}\".format(len(listOfTweets)))\n",
    "    listOfTweets = [tweet[5] for tweet in listOfTweets]\n",
    "    \n",
    "cleanTweets = list(map(dataClean, listOfTweets))\n",
    "for i in range(0,10):\n",
    "    print(\"{0} : {1} \\n\".format(listOfTweets[i], cleanTweets[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cleanTweets)\n",
    "\n",
    "df.to_csv('cleanedTweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
