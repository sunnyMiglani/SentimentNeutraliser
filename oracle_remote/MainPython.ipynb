{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import string\n",
    "import nltk\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "from IPython.display import HTML\n",
    "from nltk.corpus import wordnet \n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pathToDatasets = '../datasets/'\n",
    "pathToDataScripts = '../datasets/scripts/'\n",
    "filePath = '../datasets/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "sys.path.insert(0, pathToDataScripts)\n",
    "from cleanDataset import tokenize_words \n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading binaries and models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should I reload the model?\n",
      "no\n",
      " didnt reload model! \n"
     ]
    }
   ],
   "source": [
    "print(\"Should I reload the model?\")\n",
    "tstString = input()\n",
    "if(\"no\" in tstString.lower()):\n",
    "    print(\" didnt reload model! \")\n",
    "else:\n",
    "    print(\"loading the model!\");\n",
    "    word_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables and Global Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senty = SentimentIntensityAnalyzer()\n",
    "vocabulary = word_vectors.vocab;\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "NUMBER_OF_ALTERNATIVES = 5\n",
    "TWEET_START = 104\n",
    "NUM_OF_TWEETS = 5\n",
    "\n",
    "\n",
    "# VERBOSE_PRINTING = True\n",
    "VERBOSE_PRINTING = False\n",
    "\n",
    "USE_SPACY = False\n",
    "# USE_SPACY = True\n",
    "\n",
    "COLOR_PRINTING = True\n",
    "#COLOR_PRINTING = False\n",
    "\n",
    "\n",
    "\n",
    "punctuation = r\"\\\"#$%&'+-/;<=>?@[\\]*.^_`{|}~\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceWithHTML():\n",
    "    \n",
    "    def __init__(self,sentence,html):\n",
    "        self.sentence = sentence;\n",
    "        self.html = html;\n",
    "    \n",
    "    def getHTML(self):\n",
    "        return self.html;\n",
    "    \n",
    "    def getSentence(self):\n",
    "        return self.sentence\n",
    "    \n",
    "    def setHTML(self, html):\n",
    "        self.html = html;\n",
    "    \n",
    "    def setSentence(self, sentence):\n",
    "        self.sentence = sentence\n",
    "\n",
    "\n",
    "class Sentence:\n",
    "    \n",
    "    \n",
    "    def __init__(self, sentence, sentiment):\n",
    "        self.ogSentence = sentence;\n",
    "        self.ogSentiment = sentiment;\n",
    "        self.indexToSetOfWords = {}\n",
    "        self.alternateSentences = [];\n",
    "        self.finalShiftSentences = [];\n",
    "\n",
    "    def addAlternativesByIndex(self, index, listOfAlternatives):\n",
    "        '''\n",
    "            Adds the list of possible alternative words that \n",
    "            can be used per word based on the index of the word in the tokenized \n",
    "            sentence. (from cleanAndTokenizeText())\n",
    "        '''\n",
    "        if(self.indexToSetOfWords.get(index)):\n",
    "            self.indexToSetOfWords[index] = self.indexToSetOfWords.union(set(listOfAlternatives))\n",
    "        else:\n",
    "            self.indexToSetOfWords[index] = set(listOfAlternatives)\n",
    "        \n",
    "    def addAlternativeStrings(self, strings):\n",
    "        if(isinstance(strings,str)):\n",
    "            self.alternateStrings = list(set(self.alternateStrings.append(strings)))\n",
    "            self.alternateSentences.append(strings)\n",
    "        else:\n",
    "            self.alternateSentences.extend(strings)\n",
    "    \n",
    "\n",
    "    \n",
    "    def addFinalSentences(self, sentences):\n",
    "        if(isinstance(sentences, str)):\n",
    "            self.finalShiftSentences.append(sentences)\n",
    "        else:\n",
    "            self.finalShiftSentences.extend(sentences)\n",
    "\n",
    "    def resetFinalSentences(self):\n",
    "        self.finalShiftSentences = [];\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printStrings(sentenceObj):\n",
    "    newStrings = sentenceObj.finalShiftSentences;\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "    for ind, tSentence in enumerate(newStrings):\n",
    "            alteredTweet = tSentence.getSentence()\n",
    "            htmlText = tSentence.getHTML()\n",
    "            sentimentOfNewString = senty.polarity_scores(alteredTweet)['compound']\n",
    "            if(sentimentOfNewString == mainSentiment or sentimentOfNewString == 0):\n",
    "                displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString), 'DarkGray');\n",
    "            elif(sentimentOfNewString > mainSentiment):\n",
    "                displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'green')\n",
    "            else:\n",
    "                displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cstr(s, color='black', italics=False):\n",
    "    if(COLOR_PRINTING):\n",
    "        if(italics):\n",
    "            return cstr(\"<i>{0}</i>\".format(s), color);\n",
    "        return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "    else:\n",
    "        return \"{}\".format(s)\n",
    "\n",
    "def displayText(text, color='black'):\n",
    "    if(COLOR_PRINTING):\n",
    "        display(HTML(cstr(text, color)));\n",
    "        return\n",
    "    print(\"{}\".format(text));\n",
    "    \n",
    "    \n",
    "def cleanAndTokenizeText(text):\n",
    "    text = text.lower();\n",
    "    newString = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            newString += char\n",
    "    text = word_tokenize(newString)\n",
    "    return text;\n",
    "\n",
    "def getPOSTags(tweet):\n",
    "    if(USE_SPACY == False):\n",
    "        tags = nltk.pos_tag(tweet)\n",
    "        return tags;    \n",
    "    tweet = ' '.join(tweet)\n",
    "    doc = nlp(tweet)\n",
    "    tags = [(token.text, token.pos_) for token in doc] # since the format expected is [text,tag]\n",
    "    return tags;\n",
    "    \n",
    "\n",
    "def getAntonymsOfWords(word):\n",
    "    if(word not in vocabulary):\n",
    "        return []\n",
    "    setOfAntonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            anton = l.antonyms()\n",
    "            if(anton!=[]):\n",
    "                setOfAntonyms.add(anton[0].name())\n",
    "    if(len(setOfAntonyms) == 0):\n",
    "        if(VERBOSE_PRINTING): print(\"No antonyms found for word {0}\".format(word))\n",
    "    return list(setOfAntonyms)\n",
    "\n",
    "def listReplacements(word):\n",
    "    if(word not in vocabulary):\n",
    "        print(\" --- {0} not in vocabulary ---\".format(word))\n",
    "        return []\n",
    "    possibleReplacements = [word[0] for word in word_vectors.most_similar(word,topn=NUMBER_OF_ALTERNATIVES)]\n",
    "    if(possibleReplacements == []):\n",
    "        print(\" --- No replacements for word {0} ---\".format(word))\n",
    "    antonyms = getAntonymsOfWords(word)\n",
    "    if(antonyms != []):\n",
    "        possibleReplacements.extend(antonyms)\n",
    "        if(VERBOSE_PRINTING): print(\"Some antonyms for word {0} are {1}\".format(word, antonyms[:3]))\n",
    "        return possibleReplacements\n",
    "    return possibleReplacements\n",
    "    \n",
    "def posApprovedReplacements(alternativeWords, userTokens, indexOfToken):\n",
    "    if(alternativeWords == []):\n",
    "        return []\n",
    "    tempTokens = userTokens[:]\n",
    "    POSTokens = getPOSTags(tempTokens)\n",
    "    validWords = []\n",
    "    \n",
    "    mainTag = POSTokens[indexOfToken][1]\n",
    "    mainWord = userTokens[indexOfToken]\n",
    "    \n",
    "    for ind,word in enumerate(alternativeWords):\n",
    "        tempTokens[indexOfToken] = word\n",
    "        posTags = getPOSTags(tempTokens)\n",
    "        newTag = (posTags[indexOfToken])[1]\n",
    "        \n",
    "        if(str(newTag) == str(mainTag)):\n",
    "            if(VERBOSE_PRINTING): print(\"Word {0}[{1}] replaced with {2}[{3}]\".format(mainWord, mainTag, word,newTag))\n",
    "            validWords.append(word)\n",
    "    if(validWords == [] and VERBOSE_PRINTING):\n",
    "        print(\"No POS words found for word {} with tag {}\".format(mainWord, mainTag));\n",
    "    return validWords\n",
    "        \n",
    "    \n",
    "    \n",
    "def getAlternativeSentences(sentenceObj):\n",
    "    mainSentence = sentenceObj.ogSentence;\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "\n",
    "    sentenceTokens = cleanAndTokenizeText(mainSentence)\n",
    "\n",
    "    for ind, word in enumerate(sentenceTokens):\n",
    "        alternativeSentenceWithHTML = []\n",
    "\n",
    "        score = senty.polarity_scores(word)['compound']\n",
    "        copyOfTokens = sentenceTokens[:]\n",
    "        replacements = []\n",
    "        if(score != 0.0):\n",
    "            tempReplacements = listReplacements(word) # get embedding based relations\n",
    "            if(tempReplacements == []):\n",
    "                print(\"No replacements found at all for word {0}\".format(word))\n",
    "                continue\n",
    "            replacements = posApprovedReplacements(tempReplacements[:], copyOfTokens[:], ind)\n",
    "            if(replacements == []):\n",
    "                print(\" -- No POS approved words! -- for word {0}\\n some non-POS:{1}\".format(word, tempReplacements[:4]))\n",
    "                continue\n",
    "            sentenceObj.addAlternativesByIndex(ind, replacements)\n",
    "\n",
    "            ## Generate new sentences by switching that word\n",
    "            for newWord in replacements:\n",
    "                htmlFriendlyTokens = copyOfTokens[:]\n",
    "                copyOfTokens[ind] = newWord\n",
    "                htmlFriendlyTokens[ind] = cstr(\"[{0}]\".format(newWord), \"blue\", italics=True);\n",
    "                newString = ' '.join(copyOfTokens)\n",
    "                tSentence = SentenceWithHTML(newString, ' '.join(htmlFriendlyTokens))\n",
    "                alternativeSentenceWithHTML.append(tSentence)\n",
    "        sentenceObj.addAlternativeStrings(alternativeSentenceWithHTML)\n",
    "    return sentenceObj\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def shiftSentiment(sentenceObj, positive=True):\n",
    "    \n",
    "    actualTweet = sentenceObj.ogSentence;\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "    alternateTweets = sentenceObj.alternateSentences;\n",
    "    \n",
    "    \n",
    "    happiestTweet = \"\"\n",
    "    saddestTweet = \"\"\n",
    "    happiestScore = -sys.maxsize - 1\n",
    "    saddestScore = sys.maxsize\n",
    "    correctTweets = []\n",
    "    \n",
    "    for tSentence in alternateTweets:\n",
    "        tweet = tSentence.getSentence();\n",
    "        newSenty = senty.polarity_scores(tweet)['compound']\n",
    "        \n",
    "        if(newSenty < saddestScore):\n",
    "            saddestTweet = tSentence\n",
    "            saddestScore = newSenty\n",
    "        if(newSenty > happiestScore):\n",
    "            happiestTweet = tSentence\n",
    "            happiestScore = newSenty\n",
    "            \n",
    "        if(newSenty == mainSentiment):\n",
    "            continue\n",
    "        if(positive == True):\n",
    "            if(newSenty > mainSentiment):\n",
    "                correctTweets.append(tSentence)\n",
    "                continue\n",
    "            \n",
    "            elif(newSenty < mainSentiment):\n",
    "                continue\n",
    "                # Grab happiest tweet and if it's not \"\", then generate more happy tweets from it\n",
    "        if(positive == False):\n",
    "            if(newSenty < mainSentiment):\n",
    "                correctTweets.append(tSentence)\n",
    "                continue\n",
    "            \n",
    "            elif(newSenty > mainSentiment):\n",
    "                continue\n",
    "                # grab happiest tweet, and if it's not \"\", then generate more happy tweets from it\n",
    "                \n",
    "    if(correctTweets == []):\n",
    "        print(\"\\n\\nNo tweets found when trying to do Positive={}\\n\\n\".format(positive))\n",
    "    sentenceObj.resetFinalSentences();\n",
    "    sentenceObj.addFinalSentences(correctTweets);\n",
    "    return sentenceObj;\n",
    "\n",
    "'''\n",
    "for ind in range(0,len(reversedKeys)):\n",
    "#         key = reversedKeys[ind]\n",
    "#         prevKey = reversedKeys[ind-1] if (ind-1 <= 0) else 0\n",
    "#         thisList = getBackendList(key, prevKey,totalList, secondDictAlternatives, tokenizedSentence)\n",
    "#         totalList = thisList[:]      \n",
    "\n",
    "'''    \n",
    "    \n",
    "def getBackendList(thisKey,prevIndex, totalList,dictAlternatives, wholeSentence):\n",
    "    myOptions = dictAlternatives[thisKey]\n",
    "    newOptions = []\n",
    "    print(\"this key : {0} in getBackendList\".format(thisKey))\n",
    "    if(totalList == []):\n",
    "        return myOptions;\n",
    "    for thisOption in myOptions:\n",
    "        for thisArr in totalList: # if(VERBOSE_PRINTING): \n",
    "            print(\"Combining :{0} with {1}\".format(thisOption[:(prevIndex-thisKey)], thisArr))\n",
    "            newOptions.append(thisOption[:(prevIndex-thisKey)] + thisArr)\n",
    "    \n",
    "    return newOptions\n",
    "\n",
    "\n",
    "\n",
    "def combineSentenceChunks(wholeSentence, dictOfChunks):\n",
    "    reversedKeys = sorted(dictOfChunks.keys(), reverse=True)\n",
    "    completeSentences = [];\n",
    "    mainArr = dictOfChunks[reversedKeys[0]]\n",
    "    for ind in range(1, len(reversedKeys)):\n",
    "        key = reversedKeys[ind]\n",
    "        thisArr = dictOfChunks[key]\n",
    "        newSentences = []\n",
    "        for val in thisArr:\n",
    "            for mainVal in mainArr:\n",
    "                print(\"Combining {0} with {1}\".format(val, mainVal));\n",
    "                newSentences.append(val+ mainVal)\n",
    "                \n",
    "        completeSentences += (newSentences)\n",
    "    return completeSentences;\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "def generateSentenceChunks(wholeSentence, keyToChange, nextKey, listOfMyAlternatives):\n",
    "    newList = list(listOfMyAlternatives)\n",
    "    newList.append(wholeSentence[keyToChange]);\n",
    "    generatedSentences = []\n",
    "    for myAlt in newList:\n",
    "        newSentence = wholeSentence[:]\n",
    "        newSentence[keyToChange] = myAlt\n",
    "        if(VERBOSE_PRINTING): print(\"Generated : {}\".format(newSentence[keyToChange:nextKey]))\n",
    "        generatedSentences.append(newSentence[keyToChange:nextKey]);\n",
    "        \n",
    "    return generatedSentences\n",
    "    \n",
    "    \n",
    "def printAllPossibleStrings(sentenceObj):\n",
    "    indexToWordDict = sentenceObj.indexToSetOfWords;\n",
    "    originalSentence = sentenceObj.ogSentence;\n",
    "    tokenizedSentence = cleanAndTokenizeText(originalSentence)\n",
    "    reversedKeys = sorted(indexToWordDict.keys(), reverse=True)\n",
    "    dictAlternatives  = {}\n",
    "\n",
    "    keys = sorted(indexToWordDict.keys())\n",
    "    sentenceChunks = {}\n",
    "    print(\"Keys : {0}\".format(keys))\n",
    "    \n",
    "    for ind in range(0,len(keys)):\n",
    "        key = keys[ind]\n",
    "        nextKey = keys[ind+1] if ind+1 < len(keys) else len(tokenizedSentence)\n",
    "        sentenceChunks[key] = generateSentenceChunks(tokenizedSentence, key, nextKey, indexToWordDict[key])\n",
    "    \n",
    "\n",
    "    \n",
    "    if(keys[0] != 0):\n",
    "        newList = []\n",
    "        for thislist in sentenceChunks[keys[0]]:\n",
    "            newList.append(tokenizedSentence[0:keys[0]] + thislist)\n",
    "        sentenceChunks[keys[0]] = newList;\n",
    "        \n",
    "    print(\"Sentence Chunks generated!\")\n",
    "        \n",
    "        \n",
    "    finalOptions = combineSentenceChunks(tokenizedSentence, sentenceChunks)\n",
    "    \n",
    "    \n",
    "    for val in finalOptions:\n",
    "        print(val)\n",
    "        \n",
    "      #newSentences = []\n",
    "#     thisSentence = tokenizedSentence[:]\n",
    "#     totalList = []\n",
    "#     for ind in range(0,len(reversedKeys)):\n",
    "#         key = reversedKeys[ind]\n",
    "#         prevKey = reversedKeys[ind-1] if (ind-1 <= 0) else 0\n",
    "#         thisList = getBackendList(key, prevKey,totalList, secondDictAlternatives, tokenizedSentence)\n",
    "#         totalList = thisList[:]        \n",
    "        \n",
    "#     listInd = keys[0];\n",
    "#     for ind,arr in enumerate(totalList):\n",
    "#         totalList[ind] = tokenizedSentence[:listInd]+totalList[ind]\n",
    "        \n",
    "#     for val in totalList:\n",
    "#         print(' '.join(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I really hate hot chocolate, but i enjoy hot coffee!:0.4759\n",
      "\n",
      "Keys : [2, 8]\n",
      "Sentence Chunks generated!\n",
      "Combining ['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i'] with ['suffer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i'] with ['feel', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i'] with ['prefer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i'] with ['want', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i'] with ['enjoy', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i'] with ['suffer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i'] with ['feel', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i'] with ['prefer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i'] with ['want', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i'] with ['enjoy', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i'] with ['suffer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i'] with ['feel', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i'] with ['prefer', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i'] with ['want', 'hot', 'coffee', '!']\n",
      "Combining ['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i'] with ['enjoy', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i', 'suffer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i', 'feel', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i', 'prefer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i', 'want', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'racist', 'hot', 'chocolate', ',', 'but', 'i', 'enjoy', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i', 'suffer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i', 'feel', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i', 'prefer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i', 'want', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'fear', 'hot', 'chocolate', ',', 'but', 'i', 'enjoy', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i', 'suffer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i', 'feel', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i', 'prefer', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i', 'want', 'hot', 'coffee', '!']\n",
      "['i', 'really', 'hate', 'hot', 'chocolate', ',', 'but', 'i', 'enjoy', 'hot', 'coffee', '!']\n"
     ]
    }
   ],
   "source": [
    "specificString = \"\"\n",
    "def specificString(textString=\"\"):\n",
    "    if(textString == \"\" or textString == None):\n",
    "        return\n",
    "    mainSentiment = senty.polarity_scores(textString)['compound']\n",
    "    if(mainSentiment == 0):\n",
    "        print(\"{} \\n No sentiment found in sentence\".format(textString));\n",
    "        return;\n",
    "    print(\"\\n {0}:{1}\\n\".format(textString,mainSentiment))   \n",
    "    sentenceObj = Sentence(textString, mainSentiment)\n",
    "    sentenceObj = getAlternativeSentences(sentenceObj)\n",
    "    alternateTweets = (sentenceObj.alternateSentences)[:]\n",
    "    if(alternateTweets == [] or alternateTweets == None):\n",
    "        print(\" -- No new Strings generated ---\\n\\n\")\n",
    "        return\n",
    "    printStrings(sentenceObj)\n",
    "    printAllPossibleStrings(sentenceObj)\n",
    "\n",
    "specificString(\"I really hate hot chocolate, but i enjoy hot coffee!\")\n",
    "# specificString(\"would rather the first party send bad messages than the 3rd party send mixed ones  sophmore year all over again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  remember my bum leg strikes back this time its serious :-0.4215\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>remember my bum leg <text style=color:blue><i>[airstrikes]</i></text> back this time its serious: -0.0772</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>remember my bum leg <text style=color:blue><i>[raids]</i></text> back this time its serious: -0.0772</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>remember my bum leg strikes back this time its <text style=color:blue><i>[possible]</i></text>: -0.3612</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>remember my bum leg strikes back this time its <text style=color:blue><i>[frivolous]</i></text>: -0.3612</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>remember my bum leg <text style=color:blue><i>[attacks]</i></text> back this time its serious: -0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>remember my bum leg strikes back this time its <text style=color:blue><i>[severe]</i></text>: -0.6249</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys : [4, 9]\n",
      "Sentence Chunks generated!\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its'] with ['possible']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its'] with ['frivolous']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its'] with ['severe']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its'] with ['serious']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its'] with ['possible']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its'] with ['frivolous']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its'] with ['severe']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its'] with ['serious']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its'] with ['possible']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its'] with ['frivolous']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its'] with ['severe']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its'] with ['serious']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its'] with ['possible']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its'] with ['frivolous']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its'] with ['severe']\n",
      "Combining ['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its'] with ['serious']\n",
      "['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its', 'possible']\n",
      "['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its', 'frivolous']\n",
      "['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its', 'severe']\n",
      "['remember', 'my', 'bum', 'leg', 'airstrikes', 'back', 'this', 'time', 'its', 'serious']\n",
      "['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its', 'possible']\n",
      "['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its', 'frivolous']\n",
      "['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its', 'severe']\n",
      "['remember', 'my', 'bum', 'leg', 'attacks', 'back', 'this', 'time', 'its', 'serious']\n",
      "['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its', 'possible']\n",
      "['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its', 'frivolous']\n",
      "['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its', 'severe']\n",
      "['remember', 'my', 'bum', 'leg', 'raids', 'back', 'this', 'time', 'its', 'serious']\n",
      "['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its', 'possible']\n",
      "['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its', 'frivolous']\n",
      "['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its', 'severe']\n",
      "['remember', 'my', 'bum', 'leg', 'strikes', 'back', 'this', 'time', 'its', 'serious']\n",
      "\n",
      "  cool i will. their are all kinds of complaints about this laptop online about overheating but no recalls :-0.4588\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of <text style=color:blue><i>[inquiries]</i></text> about this laptop online about overheating but no recalls: -0.2846</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of <text style=color:blue><i>[allegations]</i></text> about this laptop online about overheating but no recalls: -0.2846</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of <text style=color:blue><i>[accusations]</i></text> about this laptop online about overheating but no recalls: -0.4215</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of <text style=color:blue><i>[cases]</i></text> about this laptop online about overheating but no recalls: -0.2846</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of complaints about this laptop online about overheating but <text style=color:blue><i>[any]</i></text> recalls: -0.0516</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>cool i will their are all kinds of complaints about this laptop online about overheating but <text style=color:blue><i>[all]</i></text> recalls: -0.0516</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red><text style=color:blue><i>[warm]</i></text> i will their are all kinds of complaints about this laptop online about overheating but no recalls: -0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red><text style=color:blue><i>[cold]</i></text> i will their are all kinds of complaints about this laptop online about overheating but no recalls: -0.5647</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red><text style=color:blue><i>[chill]</i></text> i will their are all kinds of complaints about this laptop online about overheating but no recalls: -0.5647</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red><text style=color:blue><i>[warm]</i></text> i will their are all kinds of complaints about this laptop online about overheating but no recalls: -0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red><text style=color:blue><i>[heat]</i></text> i will their are all kinds of complaints about this laptop online about overheating but no recalls: -0.5647</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys : [0, 8, 16]\n",
      "Sentence Chunks generated!\n",
      "Combining ['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['all', 'recalls']\n",
      "Combining ['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['any', 'recalls']\n",
      "Combining ['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['no', 'recalls']\n",
      "Combining ['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['all', 'recalls']\n",
      "Combining ['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['any', 'recalls']\n",
      "Combining ['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['no', 'recalls']\n",
      "Combining ['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['all', 'recalls']\n",
      "Combining ['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['any', 'recalls']\n",
      "Combining ['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['no', 'recalls']\n",
      "Combining ['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['all', 'recalls']\n",
      "Combining ['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['any', 'recalls']\n",
      "Combining ['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['no', 'recalls']\n",
      "Combining ['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['all', 'recalls']\n",
      "Combining ['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['any', 'recalls']\n",
      "Combining ['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but'] with ['no', 'recalls']\n",
      "Combining ['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['all', 'recalls']\n",
      "Combining ['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['any', 'recalls']\n",
      "Combining ['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['no', 'recalls']\n",
      "Combining ['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['all', 'recalls']\n",
      "Combining ['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['any', 'recalls']\n",
      "Combining ['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['no', 'recalls']\n",
      "Combining ['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['all', 'recalls']\n",
      "Combining ['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['any', 'recalls']\n",
      "Combining ['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['no', 'recalls']\n",
      "Combining ['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['all', 'recalls']\n",
      "Combining ['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['any', 'recalls']\n",
      "Combining ['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['no', 'recalls']\n",
      "Combining ['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['all', 'recalls']\n",
      "Combining ['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['any', 'recalls']\n",
      "Combining ['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of'] with ['no', 'recalls']\n",
      "['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'all', 'recalls']\n",
      "['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'any', 'recalls']\n",
      "['cases', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'no', 'recalls']\n",
      "['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'all', 'recalls']\n",
      "['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'any', 'recalls']\n",
      "['allegations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'no', 'recalls']\n",
      "['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'all', 'recalls']\n",
      "['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'any', 'recalls']\n",
      "['inquiries', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'no', 'recalls']\n",
      "['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'all', 'recalls']\n",
      "['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'any', 'recalls']\n",
      "['accusations', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'no', 'recalls']\n",
      "['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'all', 'recalls']\n",
      "['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'any', 'recalls']\n",
      "['complaints', 'about', 'this', 'laptop', 'online', 'about', 'overheating', 'but', 'no', 'recalls']\n",
      "['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'all', 'recalls']\n",
      "['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'any', 'recalls']\n",
      "['chill', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'no', 'recalls']\n",
      "['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'all', 'recalls']\n",
      "['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'any', 'recalls']\n",
      "['warm', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'no', 'recalls']\n",
      "['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'all', 'recalls']\n",
      "['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'any', 'recalls']\n",
      "['cold', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'no', 'recalls']\n",
      "['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'all', 'recalls']\n",
      "['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'any', 'recalls']\n",
      "['heat', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'no', 'recalls']\n",
      "['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'all', 'recalls']\n",
      "['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'any', 'recalls']\n",
      "['cool', 'i', 'will', 'their', 'are', 'all', 'kinds', 'of', 'no', 'recalls']\n",
      "\n",
      " emily will be glad when mommy is done training at her new job. she misses her.  :0.2732\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>emily will be <text style=color:blue><i>[thankful]</i></text> when mommy is done training at her new job she misses her: 0.4215</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>emily will be <text style=color:blue><i>[happy]</i></text> when mommy is done training at her new job she misses her: 0.4215</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>emily will be glad when mommy is done training at her new job she <text style=color:blue><i>[throws]</i></text> her: 0.4588</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>emily will be glad when mommy is done training at her new job she <text style=color:blue><i>[chances]</i></text> her: 0.5859</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>emily will be glad when mommy is done training at her new job she <text style=color:blue><i>[kicks]</i></text> her: 0.4588</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>emily will be <text style=color:blue><i>[sad]</i></text> when mommy is done training at her new job she misses her: -0.6124</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys : [3, 14]\n",
      "Sentence Chunks generated!\n",
      "Combining ['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['throws', 'her']\n",
      "Combining ['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['chances', 'her']\n",
      "Combining ['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['kicks', 'her']\n",
      "Combining ['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['misses', 'her']\n",
      "Combining ['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['throws', 'her']\n",
      "Combining ['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['chances', 'her']\n",
      "Combining ['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['kicks', 'her']\n",
      "Combining ['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['misses', 'her']\n",
      "Combining ['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['throws', 'her']\n",
      "Combining ['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['chances', 'her']\n",
      "Combining ['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['kicks', 'her']\n",
      "Combining ['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['misses', 'her']\n",
      "Combining ['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['throws', 'her']\n",
      "Combining ['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['chances', 'her']\n",
      "Combining ['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['kicks', 'her']\n",
      "Combining ['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she'] with ['misses', 'her']\n",
      "['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'throws', 'her']\n",
      "['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'chances', 'her']\n",
      "['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'kicks', 'her']\n",
      "['emily', 'will', 'be', 'happy', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'misses', 'her']\n",
      "['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'throws', 'her']\n",
      "['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'chances', 'her']\n",
      "['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'kicks', 'her']\n",
      "['emily', 'will', 'be', 'sad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'misses', 'her']\n",
      "['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'throws', 'her']\n",
      "['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'chances', 'her']\n",
      "['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'kicks', 'her']\n",
      "['emily', 'will', 'be', 'thankful', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'misses', 'her']\n",
      "['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'throws', 'her']\n",
      "['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'chances', 'her']\n",
      "['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'kicks', 'her']\n",
      "['emily', 'will', 'be', 'glad', 'when', 'mommy', 'is', 'done', 'training', 'at', 'her', 'new', 'job', 'she', 'misses', 'her']\n",
      "\n",
      " would rather the first party send bad messages than the 3rd party send mixed ones  sophmore year all over again:0.2263\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>would rather the first party send <text style=color:blue><i>[good]</i></text> messages than the 3rd party send mixed ones sophmore year all over again: 0.8074</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>would rather the first party send <text style=color:blue><i>[unregretful]</i></text> messages than the 3rd party send mixed ones sophmore year all over again: 0.6597</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>would rather the first party send <text style=color:blue><i>[good]</i></text> messages than the 3rd party send mixed ones sophmore year all over again: 0.8074</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first <text style=color:blue><i>[opposition]</i></text> send bad messages than the 3rd party send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first <text style=color:blue><i>[coalition]</i></text> send bad messages than the 3rd party send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first <text style=color:blue><i>[leader]</i></text> send bad messages than the 3rd party send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first party send bad messages than the 3rd <text style=color:blue><i>[opposition]</i></text> send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first party send bad messages than the 3rd <text style=color:blue><i>[coalition]</i></text> send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>would rather the first party send bad messages than the 3rd <text style=color:blue><i>[leader]</i></text> send mixed ones sophmore year all over again: -0.2023</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys : [4, 6, 11]\n",
      "Sentence Chunks generated!\n",
      "Combining ['unregretful', 'messages', 'than', 'the', '3rd'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['unregretful', 'messages', 'than', 'the', '3rd'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['unregretful', 'messages', 'than', 'the', '3rd'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['unregretful', 'messages', 'than', 'the', '3rd'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['good', 'messages', 'than', 'the', '3rd'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['good', 'messages', 'than', 'the', '3rd'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['good', 'messages', 'than', 'the', '3rd'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['good', 'messages', 'than', 'the', '3rd'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['bad', 'messages', 'than', 'the', '3rd'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['bad', 'messages', 'than', 'the', '3rd'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['bad', 'messages', 'than', 'the', '3rd'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['bad', 'messages', 'than', 'the', '3rd'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'leader', 'send'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'leader', 'send'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'leader', 'send'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'leader', 'send'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'coalition', 'send'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'coalition', 'send'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'coalition', 'send'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'coalition', 'send'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'opposition', 'send'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'opposition', 'send'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'opposition', 'send'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'opposition', 'send'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'party', 'send'] with ['leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'party', 'send'] with ['coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'party', 'send'] with ['opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "Combining ['would', 'rather', 'the', 'first', 'party', 'send'] with ['party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['unregretful', 'messages', 'than', 'the', '3rd', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['unregretful', 'messages', 'than', 'the', '3rd', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['unregretful', 'messages', 'than', 'the', '3rd', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['unregretful', 'messages', 'than', 'the', '3rd', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['good', 'messages', 'than', 'the', '3rd', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['good', 'messages', 'than', 'the', '3rd', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['good', 'messages', 'than', 'the', '3rd', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['good', 'messages', 'than', 'the', '3rd', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['bad', 'messages', 'than', 'the', '3rd', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['bad', 'messages', 'than', 'the', '3rd', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['bad', 'messages', 'than', 'the', '3rd', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['bad', 'messages', 'than', 'the', '3rd', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'leader', 'send', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'leader', 'send', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'leader', 'send', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'leader', 'send', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'coalition', 'send', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'coalition', 'send', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'coalition', 'send', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'coalition', 'send', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'opposition', 'send', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'opposition', 'send', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'opposition', 'send', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'opposition', 'send', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'party', 'send', 'leader', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'party', 'send', 'coalition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'party', 'send', 'opposition', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n",
      "['would', 'rather', 'the', 'first', 'party', 'send', 'party', 'send', 'mixed', 'ones', 'sophmore', 'year', 'all', 'over', 'again']\n"
     ]
    }
   ],
   "source": [
    "def runThroughTweets():\n",
    "    \n",
    "    tweets_df = pd.read_csv( pathToDatasets + 'cleanedTweets.csv' , nrows=NUM_OF_TWEETS, skiprows=TWEET_START)\n",
    "\n",
    "    tweets = tweets_df.values\n",
    "\n",
    "    listOfObjects = []\n",
    "    for counter,tweet in enumerate(tweets):\n",
    "        tweet = tweet[0]\n",
    "        mainSentiment = senty.polarity_scores(tweet)['compound']\n",
    "        if(mainSentiment == 0):\n",
    "            continue\n",
    "        print(\"\\n {0}:{1}\\n\".format(tweet,mainSentiment))   \n",
    "        sentenceObj = Sentence(tweet, mainSentiment)\n",
    "        sentenceObj = getAlternativeSentences(sentenceObj)\n",
    "        alternateTweets = (sentenceObj.alternateSentences)[:]\n",
    "        if(alternateTweets == [] or alternateTweets == None):\n",
    "            print(\" -- No new Strings generated ---\\n\\n\")\n",
    "            continue\n",
    "        sentenceObj = shiftSentiment(sentenceObj, True);\n",
    "        printStrings(sentenceObj)\n",
    "        sentenceObj = shiftSentiment(sentenceObj, False);\n",
    "        printStrings(sentenceObj)\n",
    "        printAllPossibleStrings(sentenceObj)\n",
    "    \n",
    "runThroughTweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificWord = \"good\"\n",
    "def testOneWord(word=\"\"):\n",
    "    if(word==\"\"):\n",
    "        return\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
