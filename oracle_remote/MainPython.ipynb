{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import string\n",
    "import nltk\n",
    "import sys\n",
    "import spacy\n",
    "import os\n",
    "import pickle\n",
    "    \n",
    "from IPython.display import HTML\n",
    "from nltk.corpus import wordnet \n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pathToDatasets = '../datasets/'\n",
    "pathToDataScripts = '../datasets/scripts/'\n",
    "filePath = '../datasets/GoogleNews-vectors-negative300.bin'\n",
    "# modelBeingUsed = \"glove-wiki-gigaword-300\"\n",
    "# modelBeingUsed = \"glove-wiki-gigaword-100\"\n",
    "# modelBeingUsed = \"glove-twitter-50\"\n",
    "# modelBeingUsed = \"glove-twitter-100\"\n",
    "modelBeingUsed = \"glove-twitter-200\"\n",
    "\n",
    "sys.path.insert(0, pathToDataScripts)\n",
    "from cleanDataset import tokenize_words, dataClean\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading binaries and models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should I reload the model?\n",
      "no\n",
      " didnt reload model! \n",
      "{'completely', 'absolutely'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Should I reload the model?\")\n",
    "tstString = input()\n",
    "if(\"no\" in tstString.lower() or \"n\" in tstString.lower()):\n",
    "    print(\" didnt reload model! \")\n",
    "else:\n",
    "    print(\"loading {0}!\".format(modelBeingUsed));\n",
    "    fileName = \"{}.pickle\".format(modelBeingUsed)\n",
    "    if(os.path.exists(pathToDatasets+fileName)):\n",
    "        print(\"loading via pickle!\")\n",
    "        pickle_in = open(pathToDatasets+fileName, \"rb\")\n",
    "        word_vectors = pickle.load(pickle_in);\n",
    "    else:\n",
    "        print(\"Pickle didn't exist, therefore loading model!\")\n",
    "        word_vectors = api.load(\"{0}\".format(modelBeingUsed))\n",
    "        print(\"-- Saving to pickle file for next time! --\")\n",
    "        pickle_out = open(pathToDatasets+fileName,\"wb\")\n",
    "        pickle.dump(word_vectors, pickle_out)\n",
    "        pickle_out.close()\n",
    "        \n",
    "    nltk.download('vader_lexicon')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('wordnet')\n",
    "    print(\"Model Loaded!\")\n",
    "\n",
    "setOfBoosterWords = set()\n",
    "with open(pathToDatasets + \"BoosterWordList.txt\") as bwf:\n",
    "    pd_booster = pd.read_csv(bwf, sep='\\t');\n",
    "    listOfBoosterWords = (pd_booster.iloc[:,0]).tolist() \n",
    "    setOfBoosterWords = set(listOfBoosterWords[:2])\n",
    "    print(setOfBoosterWords)\n",
    "setOfBoosterWords.add(\"\") # So we have a case where we're not adding any boosters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables and Global Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "senty = SentimentIntensityAnalyzer()\n",
    "vocabulary = word_vectors.vocab;\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "'''\n",
    "Good sets -> {100+20}\n",
    "'''\n",
    "NUMBER_OF_ALTERNATIVES = 6\n",
    "TWEET_START = 10\n",
    "NUM_OF_TWEETS = 100\n",
    "\n",
    "# VERBOSE_PRINTING = True\n",
    "VERBOSE_PRINTING = False\n",
    "\n",
    "# USE_SPACY = False\n",
    "USE_SPACY = True\n",
    "\n",
    "COLOR_PRINTING = True\n",
    "# COLOR_PRINTING = False\n",
    "\n",
    "# PRINT_NEUTRAL = True\n",
    "PRINT_NEUTRAL = False\n",
    "\n",
    "# PRINT_ALL_STRINGS = True\n",
    "PRINT_ALL_STRINGS = False\n",
    "\n",
    "SHOW_ALTS = 50\n",
    "\n",
    "MAX_SENTIMENT_HEAVY_WORDS = 5\n",
    "\n",
    "punctuation = r\"\\\"#$%&'+-/;<=>?@[\\]*^_`{|}~\"\n",
    "LIST_OF_NEGATIONS = [\"not\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentenceClass import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStrings(sentenceObj):\n",
    "    \n",
    "    numberOfPrints = 0\n",
    "    newStrings = generateHTMLObjectsFromSentence(sentenceObj)\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "    listOfSentencesWithSentiments = []\n",
    "    bestSentiment = -sys.maxsize - 1\n",
    "    worstSentiment = sys.maxsize\n",
    "    \n",
    "    isPositiveSentence = True if(mainSentiment >= 0) else False\n",
    "    \n",
    "    bestSentimentString = \"\";\n",
    "    worstSentimentString = \"\";\n",
    "    \n",
    "    numberOfSentimentHeavyWordsYet = 0;\n",
    "    for ind, tSentence in enumerate(newStrings):\n",
    "            alteredTweet = tSentence.getSentence()\n",
    "            htmlText = tSentence.getHTML()\n",
    "            numberOfPrints+=1;\n",
    "            \n",
    "            \n",
    "            sentimentOfNewString = senty.polarity_scores(alteredTweet)['compound']\n",
    "            \n",
    "            thisStringPositive = True if(sentimentOfNewString >= 0) else False\n",
    "            if(thisStringPositive != isPositiveSentence):\n",
    "                continue\n",
    "            \n",
    "            newObj = SentenceWithSentiment(alteredTweet, sentimentOfNewString, htmlText)\n",
    "            listOfSentencesWithSentiments.append(newObj)\n",
    "            \n",
    "            if(sentimentOfNewString >= bestSentiment):\n",
    "                bestSentiment = sentimentOfNewString\n",
    "                bestSentimentString = htmlText;\n",
    "            elif(sentimentOfNewString < worstSentiment):\n",
    "                worstSentiment = sentimentOfNewString\n",
    "                worstSentimentString = htmlText;\n",
    "            \n",
    "            \n",
    "#             if(numberOfPrints > SHOW_ALTS): break\n",
    "            if(numberOfPrints > SHOW_ALTS or PRINT_ALL_STRINGS == False): continue\n",
    "            if(sentimentOfNewString == mainSentiment or sentimentOfNewString == 0.0):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'black')\n",
    "            elif(sentimentOfNewString > mainSentiment):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'green')\n",
    "            elif(sentimentOfNewString < mainSentiment and sentimentOfNewString != 0.0):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'red')\n",
    "                \n",
    "    if(numberOfPrints > SHOW_ALTS): print(\"--- More options (total: {0}) possible, but not printed ---\".format(numberOfPrints));\n",
    "    displayText(\"Actual Sentence: {0} :{1}\".format(sentenceObj.ogSentence, sentenceObj.ogSentiment))\n",
    "    if (worstSentimentString != \"\"): displayText(\"Worst Sentence: {0} : {1}\".format(worstSentimentString, worstSentiment), color='red')\n",
    "    if (bestSentimentString != \"\"): displayText(\"Best Sentence: {0} : {1}\".format(bestSentimentString, bestSentiment), color='green') \n",
    "    \n",
    "    \n",
    "    sentenceObj.addFinalSentences(listOfSentencesWithSentiments)\n",
    "    return listOfSentencesWithSentiments, sentenceObj;\n",
    "\n",
    "def cstr(s, color='black', italics=False):\n",
    "    if(COLOR_PRINTING):\n",
    "        if(italics):\n",
    "            return cstr(\"<i>{0}</i>\".format(s), color);\n",
    "        return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "    else:\n",
    "        return \"{}\".format(s)\n",
    "\n",
    "def displayText(text, color='black'):\n",
    "    if(COLOR_PRINTING):\n",
    "        display(HTML(cstr(text, color)));\n",
    "        return\n",
    "    print(\"{}\".format(text));\n",
    "    \n",
    "    \n",
    "def cleanAndTokenizeText(text):\n",
    "    text = text.lower();\n",
    "    newString = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            newString += char\n",
    "    text = word_tokenize(newString)\n",
    "    return text;\n",
    "\n",
    "def getPOSTags(tweet):\n",
    "    if(USE_SPACY == False):\n",
    "        tags = nltk.pos_tag(tweet)\n",
    "        return tags;    \n",
    "    tweet = ' '.join(tweet)\n",
    "    doc = nlp(tweet)\n",
    "    tags = [(token.text, token.tag_) for token in doc] # since the format expected is [text,tag]\n",
    "    return tags\n",
    "\n",
    "def getAntonymsAndSynonymsOfWords(word):\n",
    "    if(word not in vocabulary):\n",
    "        return [], []\n",
    "    setOfAntonyms = set()\n",
    "    setOfSynonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            setOfSynonyms.add(l.name().lower())\n",
    "            anton = l.antonyms()\n",
    "            if(anton!=[]):\n",
    "                setOfAntonyms.add(anton[0].name().lower())\n",
    "    if(len(setOfAntonyms) == 0):\n",
    "        if(VERBOSE_PRINTING): print(\"No antonyms found for word {0}\".format(word))\n",
    "    if(len(setOfSynonyms) == 0):\n",
    "        if(VERBOSE_PRINTING): print(\"No synonyms found for word {0}\".format(word))\n",
    "            \n",
    "    return [], list(setOfSynonyms)\n",
    "#     return list(setOfAntonyms), list(setOfSynonyms)\n",
    "\n",
    "\n",
    "def returnReplacementsForWord(word):\n",
    "    \n",
    "    if(word not in vocabulary):\n",
    "        print(\" --- {0} not in vocabulary ---\".format(word))\n",
    "        return []\n",
    "    possibleReplacements = [word[0] for word in word_vectors.most_similar(word,topn=NUMBER_OF_ALTERNATIVES)]\n",
    "    \n",
    "    if(possibleReplacements == []):\n",
    "        print(\" --- No replacements for word {0} ---\".format(word))\n",
    "    antonyms,synonyms = getAntonymsAndSynonymsOfWords(word)\n",
    "    \n",
    "    if(antonyms != []):\n",
    "        possibleReplacements.extend(antonyms)\n",
    "        if(VERBOSE_PRINTING): print(\"Some antonyms for word {0} are {1}\".format(word, antonyms[:3]))\n",
    "    if(synonyms != []):\n",
    "        possibleReplacements.extend(synonyms)\n",
    "        if(VERBOSE_PRINTING): print(\"Some synonyms for word {0} are {1}\".format(word, synonyms[:3]))\n",
    "    return possibleReplacements\n",
    "    \n",
    "def posApprovedReplacements(alternativeWords, userTokens, indexOfToken):\n",
    "    if(alternativeWords == []):\n",
    "        return []\n",
    "    tempTokens = userTokens[:]\n",
    "    POSTokens = getPOSTags(tempTokens)\n",
    "    validWords = []\n",
    "    \n",
    "    mainTag = POSTokens[indexOfToken][1]\n",
    "    mainWord = userTokens[indexOfToken]\n",
    "    \n",
    "    for ind,word in enumerate(alternativeWords):\n",
    "        if(\"_\" in word): continue\n",
    "        tempTokens[indexOfToken] = word\n",
    "        posTags = getPOSTags(tempTokens)\n",
    "        newTag = (posTags[indexOfToken])[1]\n",
    "        if(str(newTag) == str(mainTag)):\n",
    "#             if(VERBOSE_PRINTING): print(\"Word {0}[{1}] matched with {2}[{3}]\".format(mainWord, mainTag, word,newTag))\n",
    "            validWords.append(word)\n",
    "    if(validWords == [] and VERBOSE_PRINTING):\n",
    "        print(\"No POS words found for word {} with tag {}\".format(mainWord, mainTag));\n",
    "    return validWords\n",
    "    \n",
    "def editBoosterWords(sentenceObj):\n",
    "    ogSentence = sentenceObj.ogSentence;\n",
    "    \n",
    "    tokenizedSentence = cleanAndTokenizeText(ogSentence)\n",
    "    \n",
    "    '''\n",
    "        Use the indexToAlternatives dictionary to add words into the sentences, as part of the chunking process \n",
    "        The problem with this instinctively is how do you have an index \"between\" two variables \n",
    "        You can't really. You'd have to have a flag that says which places it's meant to go \n",
    "        You could do it _before_ the sentiment heavy word (this makes more natural sense) or \n",
    "            you could do it _after_ the word before the sentiment heavy word (this could have its own advantages) \n",
    "    '''\n",
    "    \n",
    "    posTagsForWords = getPOSTags(tokenizedSentence)    \n",
    "    for ind,(word,tag) in enumerate(posTagsForWords):    \n",
    "        if(word in setOfBoosterWords):\n",
    "            tmp = ' '.join(tokenizedSentence[ind:ind+3])\n",
    "            if(senty.polarity_scores(tmp)['compound'] != 0):\n",
    "                sentenceObj.addAlternativesByIndex(ind, [\"IGNORE_FLAG\", word]);\n",
    "                continue\n",
    "        elif(senty.polarity_scores(word)['compound'] != 0 and (\"RB\" in tag or \"JJ\" in tag or \"VB\" in tag)):  # \"JJ\" in tag and\n",
    "            newInd = ind-1 if ((ind-1) >= 0 ) else 0\n",
    "            sentenceObj.addAlternativesByIndex(newInd, [\"BOOSTER_FLAG\"]);\n",
    "            if(VERBOSE_PRINTING): print(\"Placed booster at {0} from word {1} on word {2}\".format(newInd, word,tokenizedSentence[newInd] ))\n",
    "    \n",
    "    return sentenceObj\n",
    "\n",
    "\n",
    "def generateHTMLObjectsFromSentence(sentenceObj):\n",
    "    \n",
    "    allSentences = sentenceObj.getFinalSentences()\n",
    "    indexToAlts = sentenceObj.indexToSetOfWords;\n",
    "    indexToChange = list(indexToAlts.keys());\n",
    "    \n",
    "    numberOfNegationsRemoved = 0;\n",
    "    listOfSentenceObjs = []\n",
    "    for t_sentenceObj in allSentences:\n",
    "        sentence = t_sentenceObj.getSentence()\n",
    "        sentence = t_sentenceObj.getSentence()\n",
    "        copySentence = cleanAndTokenizeText(sentence)\n",
    "        subIndex = 0\n",
    "        for index in sorted(indexToChange):\n",
    "            if(index > len(copySentence)):  \n",
    "                copySentence[len(copySentence) - index] = cstr(\"[{0}]\".format(copySentence[len(copySentence) - index]), \"blue\", italics=True);\n",
    "                continue\n",
    "            else:\n",
    "                if(\"IGNORE_FLAG\" in indexToAlts[index]):\n",
    "                    if(copySentence[index] in LIST_OF_NEGATIONS):\n",
    "                        continue; ## Word that _should_ be removed is present.\n",
    "                    else:\n",
    "                        subIndex +=1\n",
    "                        numberOfNegationsRemoved +=1;\n",
    "                        continue;\n",
    "                        \n",
    "                if(\"BOOSTER_FLAG\" in indexToAlts[index]):\n",
    "                    copySentence[index] = cstr(\"[{0}]\".format(copySentence[index]), \"blue\", italics=True);\n",
    "#                     copySentence[index+2] = cstr(\"[{0}]\".format(copySentence[index+2]), \"blue\", italics=True);\n",
    "                    continue\n",
    "                    \n",
    "            copySentence[index-subIndex] = cstr(\"[{0}]\".format(copySentence[index-subIndex]), \"blue\", italics=True);\n",
    "        listOfSentenceObjs.append(SentenceWithHTML(sentence, ' '.join(copySentence)));\n",
    "    \n",
    "    if(VERBOSE_PRINTING): print(\"Number of negations removed : {0}\".format(numberOfNegationsRemoved))\n",
    "    return listOfSentenceObjs\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Chunking and Appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_combine(mainList, myList):\n",
    "    '''\n",
    "    helper function for CombineSentenceChunks\n",
    "    '''\n",
    "    newList = []\n",
    "    for val in myList:\n",
    "        for mainVal in mainList:\n",
    "#             if(VERBOSE_PRINTING): print(\"Combining {0} with {1}\".format(' '.join(val), ' '.join(mainVal)));\n",
    "            newList.append(val + mainVal);\n",
    "    return newList;\n",
    "\n",
    "def combineSentenceChunks(wholeSentence, dictOfChunks):\n",
    "    '''\n",
    "        Uses the helper_combine function to generate all possible combinatios and permuations of the chunks\n",
    "        and any alternatives.\n",
    "        \n",
    "        The logic is to use the end of the sentence, apply each possible chunk from the previous key's chunks\n",
    "        to every possible chunk of this key's.\n",
    "        \n",
    "        The helper function is used to allow us to reuse the list of alreadyGeneratedChunks and constantly\n",
    "        append to them.\n",
    "        \n",
    "        To understand the logic better, take a look at this gist:\n",
    "        https://gist.github.com/sunnyMiglani/cf85407a9e6928237b1436cc2bc95fa4\n",
    "        \n",
    "    '''\n",
    "    reversedKeys = sorted(dictOfChunks.keys(), reverse=True)\n",
    "    completeSentences = [];\n",
    "    mainArr = dictOfChunks[reversedKeys[0]]\n",
    "    for ind in range(1, len(reversedKeys)):\n",
    "        key = reversedKeys[ind];\n",
    "        mainArr = helper_combine(mainArr, dictOfChunks[key]);\n",
    "        \n",
    "    return mainArr;\n",
    "        \n",
    "def generateSentenceChunks(wholeSentence, keyToChange, nextKey, listOfMyAlternatives):\n",
    "    '''\n",
    "        Generates sentence chunks by iterating through the list of alternatives\n",
    "        Chunking the sentence to start from current key to next key.\n",
    "        This means that the sentence always goes from key 'x' to key 'y'\n",
    "        \n",
    "        Example:\n",
    "        \"I really <hate> hot chocolate, but I <prefer> hot coffee\"\n",
    "        Calling generateSentenceChunks will create an example sentence:\n",
    "            - \"<altWordForHate> hot chocolate , but I \"\n",
    "        \n",
    "        Remember to append the first stretch of the string to the first key's chunk for proper use!\n",
    "    '''\n",
    "    \n",
    "    newList = list(listOfMyAlternatives)\n",
    "    newList.append(wholeSentence[keyToChange]);\n",
    "    generatedSentences = []\n",
    "    \n",
    "        \n",
    "    for myAlt in newList:\n",
    "        if(\"IGNORE_FLAG\" == myAlt):\n",
    "            newSentence = wholeSentence[keyToChange+1:nextKey];\n",
    "            generatedSentences.append(newSentence)\n",
    "            continue\n",
    "        elif(\"BOOSTER_FLAG\" == myAlt): \n",
    "            for booster in setOfBoosterWords:\n",
    "                newSentence = wholeSentence[:]\n",
    "                newSentence.insert(keyToChange+1, booster)\n",
    "                generatedSentences.append(newSentence[keyToChange:nextKey+1]);\n",
    "        else:\n",
    "            newSentence = wholeSentence[:]\n",
    "            newSentence[keyToChange] = myAlt\n",
    "            generatedSentences.append(newSentence[keyToChange:nextKey]);\n",
    "        \n",
    "    return generatedSentences\n",
    "    \n",
    "def returnCombinationsOfStrings(sentenceObj):\n",
    "    \n",
    "    indexToWordDict = sentenceObj.indexToSetOfWords;\n",
    "    originalSentence = sentenceObj.ogSentence;\n",
    "    tokenizedSentence = cleanAndTokenizeText(originalSentence)\n",
    "    reversedKeys = sorted(indexToWordDict.keys(), reverse=True)\n",
    "    dictAlternatives  = {}\n",
    "\n",
    "    sortedKeys = sorted(indexToWordDict.keys())\n",
    "    sentenceChunks = {}\n",
    "    htmlChunks = {}\n",
    "    \n",
    "    for ind in range(0,len(sortedKeys)):\n",
    "        key = sortedKeys[ind]\n",
    "        nextKey = sortedKeys[ind+1] if ind+1 < len(sortedKeys) else len(tokenizedSentence)\n",
    "        sentenceChunks[key] = generateSentenceChunks(tokenizedSentence, key, nextKey, indexToWordDict[key])\n",
    "\n",
    "    if(sortedKeys[0] != 0):\n",
    "        newList = []\n",
    "        for thislist in sentenceChunks[sortedKeys[0]]:\n",
    "            newList.append(tokenizedSentence[0:sortedKeys[0]] + thislist)\n",
    "        sentenceChunks[sortedKeys[0]] = newList;\n",
    "        \n",
    "    finalOptions = combineSentenceChunks(tokenizedSentence, sentenceChunks)\n",
    "    \n",
    "    finalSentences = []\n",
    "    for val in finalOptions:\n",
    "        sentence = ' '.join(val)\n",
    "        sentiment = senty.polarity_scores(sentence)['compound']\n",
    "        finalSentences.append(SentenceWithSentiment(sentence,sentiment))\n",
    "    \n",
    "    sentenceObj.addFinalSentences(finalSentences)   \n",
    "    return sentenceObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAlternativeWords(sentenceObj):\n",
    "    mainSentence = sentenceObj.ogSentence;\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "\n",
    "    sentenceTokens = cleanAndTokenizeText(mainSentence)\n",
    "\n",
    "    numberOfSentimentHeavyWords = 0;\n",
    "    for ind, word in enumerate(sentenceTokens):\n",
    "        alternativeSentenceWithHTML = []\n",
    "        copyOfTokens = sentenceTokens[:]\n",
    "        replacements = []\n",
    "        replacements = sentenceObj.checkIfWordExists(word)\n",
    "        if(replacements != []):\n",
    "            print(\"FOUND REPEATED WORD {0}\".format(word))\n",
    "            sentenceObj.addAlternativesByIndex(ind, replacements)\n",
    "            continue;\n",
    "        \n",
    "        synsetOf_word = wordnet.synsets(word)\n",
    "        \n",
    "        if(word in LIST_OF_NEGATIONS):\n",
    "            '''\n",
    "                If the word is in the list of negations\n",
    "                We add a [IGNORE_FLAG] tag to the alternatives\n",
    "                Which will be grabbed in the future by the sentence generation algorithm. (chunking)\n",
    "            '''\n",
    "            tmp = ' '.join(sentenceTokens[ind:ind+3])\n",
    "            if(senty.polarity_scores(tmp)['compound'] != 0):\n",
    "                sentenceObj.addAlternativesByIndex(ind, [\"IGNORE_FLAG\", word]);\n",
    "                continue\n",
    "        \n",
    "        score = senty.polarity_scores(word)['compound']\n",
    "        if(score != 0.0):\n",
    "            if(numberOfSentimentHeavyWords < MAX_SENTIMENT_HEAVY_WORDS):\n",
    "                numberOfSentimentHeavyWords+=1;\n",
    "            else:\n",
    "                return sentenceObj\n",
    "            \n",
    "            tempReplacements = returnReplacementsForWord(word) # get embedding based relations\n",
    "            if(VERBOSE_PRINTING): print(\"Some early replacements for word [{0}] are {1}\".format(word, tempReplacements[0:8]))\n",
    "            if(tempReplacements == []):\n",
    "                print(\"No replacements found at all for word {0}\".format(word))\n",
    "                continue\n",
    "            replacements = posApprovedReplacements(tempReplacements[:], copyOfTokens[:], ind)\n",
    "            finalReplacements = []\n",
    "            if(VERBOSE_PRINTING): skippedWords = []\n",
    "            \n",
    "            ## Now removing words that aren't valid\n",
    "            \n",
    "            for new_word in replacements:\n",
    "                thisSentiment = senty.polarity_scores(new_word)['compound']\n",
    "                if(thisSentiment != 0.0):\n",
    "                    finalReplacements.append(new_word)\n",
    "                else:\n",
    "                    if(VERBOSE_PRINTING):\n",
    "                        skippedWords.append(new_word)\n",
    "            if(VERBOSE_PRINTING and len(skippedWords) > 0):\n",
    "                print(\"some skipped words: {0}\".format(skippedWords[:5]));\n",
    "                \n",
    "            \n",
    "            if(finalReplacements == []):\n",
    "                if(VERBOSE_PRINTING): print(\" -- No POS approved words! -- for word {0}\\n some non-POS:{1}\".format(word, tempReplacements[:4]))\n",
    "                continue\n",
    "            sentenceObj.addAlternativesByIndex(ind, finalReplacements)\n",
    "            sentenceObj.addWordToAlternatives(word, finalReplacements)\n",
    "    return sentenceObj\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactionHelper(dictOfAltObjs, sentiments, thisSent, lastWorkingIndex=0):\n",
    "    if(thisSent in sentiments):\n",
    "        mainIndex = sentiments.index(thisSent)\n",
    "        \n",
    "    else:\n",
    "        mainIndex = lastWorkingIndex\n",
    "    \n",
    "    numLower =  mainIndex  # Mod to keep it in range 0 -> val \n",
    "    numHigher = len(sentiments) - mainIndex - 1\n",
    "\n",
    "    print(\"There are totally {0} possible sentences\".format(len(sentiments)))\n",
    "    print(\"Current sentiment is at index {0}, and length of sentiments is {1}\".format(mainIndex, len(sentiments)));\n",
    "    print(\" <--- {0} lower and {1} ---> higher \".format(numLower, numHigher))\n",
    "    print(\"Would you like to see a lower sentiment or higher sentiment or ALL?\")\n",
    "    print(\"Please enter 1 for lower, 2 for higher or 0 for all\")\n",
    "    \n",
    "    targetSentiment = thisSent\n",
    "    textInput = input()\n",
    "    if(textInput == \"\"):\n",
    "        print(\"You entered nothing! exiting\")\n",
    "        return\n",
    "        \n",
    "    if(textInput.isdigit()):\n",
    "        textInput = int(textInput)\n",
    "        if(textInput == 0):\n",
    "            if(VERBOSE_PRINTING): print(\"Printing sentiments from : {0}\".format(sentiments))\n",
    "            for sentiment in sentiments:\n",
    "                obj = dictOfAltObjs[sentiment][0];\n",
    "                displayText(\"{0}  : {1}\".format(obj.getHTML(), sentiment))\n",
    "            return\n",
    "        elif(textInput == 1 and numLower > 0 and (mainIndex - 1) >= 0):\n",
    "            targetSentiment = sentiments[mainIndex - 1]\n",
    "            htmlSentence = dictOfAltObjs[targetSentiment][0].getHTML();\n",
    "            displayText(\"{0} : {1}\".format(htmlSentence, targetSentiment))\n",
    "            \n",
    "        elif(textInput == 2 and numHigher < len(sentiments) and (mainIndex + 1) < len(sentiments)):\n",
    "            targetSentiment = sentiments[mainIndex + 1]\n",
    "            htmlSentence = dictOfAltObjs[targetSentiment][0].getHTML();\n",
    "            displayText(\"{0} : {1}\".format(htmlSentence, targetSentiment))\n",
    "            \n",
    "        else:\n",
    "            print(\"You entered an invalid option\")\n",
    "            interactionHelper(dictOfAltObjs, sentiments, thisSent, mainIndex)\n",
    "            return\n",
    "        \n",
    "    interactionHelper(dictOfAltObjs, sentiments, targetSentiment,mainIndex)\n",
    "\n",
    "\n",
    "\n",
    "def interactionWithUser(mainSentenceObj, dictOfAltObjs,sentiments, isUser=False):\n",
    "    if(isUser == False):\n",
    "        return\n",
    "    else:\n",
    "        mainSentence = mainSentenceObj.ogSentence;\n",
    "        mainSent = mainSentenceObj.ogSentiment;\n",
    "        if(VERBOSE_PRINTING):\n",
    "            print(\"The following are the sentiment values for the input\")\n",
    "            for ind,sent in enumerate(sentiments):\n",
    "                print(\"{0} - {1}\".format(ind+1,sent))\n",
    "        \n",
    "        interactionHelper(dictOfAltObjs, sentiments, mainSent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  i could not bear to watch it.  and i thought the ua loss was embarrassing . . . . .:-0.5994\n",
      "\n",
      "--- More options (total: 140) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i could not bear to watch it.  and i thought the ua loss was embarrassing . . . . . :-0.5994</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: i could not bear to watch it . and i thought the ua <text style=color:blue><i>[deprivation]</i></text> <text style=color:blue><i>[was]</i></text> <text style=color:blue><i>[completely]</i></text> pathetic . . . . . : -0.7778</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: i could not bear to watch it . and i thought the ua <text style=color:blue><i>[deprivation]</i></text> <text style=color:blue><i>[was]</i></text> <text style=color:blue><i>[hilarious]</i></text> . . . . . : -0.0258</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  it it counts idk why i did either. you never talk to me anymore :-0.1027\n",
      "\n",
      " -- No new Strings generated ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Tweet:  i would have been the first but i did not have a gun.    not really though zac snyder is just a doucheclown.:0.3724\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i would have been the first but i did not have a gun.    not really though zac snyder is just a doucheclown. :0.3724</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: i would have been the first but i did not have a <text style=color:blue><i>[gun]</i></text> . not really though zac snyder is just a doucheclown . : 0.3724</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: i would have been the first but i did not have a <text style=color:blue><i>[assault]</i></text> . not really though zac snyder is just a doucheclown . : 0.6259</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  i wish i got to watch it with you!! i miss you and @iamlilnicki  how was the premiere!:0.4545\n",
      "\n",
      "--- More options (total: 640) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i wish i got to watch it with you!! i miss you and @iamlilnicki  how was the premiere! :0.4545</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[wish]</i></text> i got to watch it with you ! ! <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[lose]</i></text> you and iamlilnicki how was the premiere ! : 0.0</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[absolutely]</i></text> care i got to watch it with you ! <text style=color:blue><i>[!]</i></text> <text style=color:blue><i>[i]</i></text> absolutely love you and iamlilnicki how was the premiere ! : 0.8709</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: hollis death scene will hurt me severely to watch on film  wry is directors cut not out now:-0.9081\n",
      "\n",
      "--- More options (total: 35840) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: hollis death scene will hurt me severely to watch on film  wry is directors cut not out now :-0.9081</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: hollis <text style=color:blue><i>[murder]</i></text> scene <text style=color:blue><i>[will]</i></text> <text style=color:blue><i>[completely]</i></text> <text style=color:blue><i>[anguish]</i></text> <text style=color:blue><i>[me]</i></text> completely badly to watch on film <text style=color:blue><i>[wry]</i></text> <text style=color:blue><i>[is]</i></text> directors completely cut not out now : -0.9401</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: hollis <text style=color:blue><i>[destruction]</i></text> scene <text style=color:blue><i>[will]</i></text> <text style=color:blue><i>[absolutely]</i></text> <text style=color:blue><i>[smart]</i></text> <text style=color:blue><i>[me]</i></text> seriously to watch on film wry <text style=color:blue><i>[is]</i></text> <text style=color:blue><i>[directors]</i></text> cut not out now : -0.5818</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  ahh ive always wanted to see rent  love the soundtrack!!:0.6988\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  ahh ive always wanted to see rent  love the soundtrack!! :0.6988</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: ahh ive always wanted to see rent <text style=color:blue><i>[dear]</i></text> the soundtrack ! ! : 0.4912</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: ahh ive always wanted to see rent <text style=color:blue><i>[love]</i></text> the soundtrack ! ! : 0.6988</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  oh dear. were you drinking out of the forgotten table drinks :0.1779\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  oh dear. were you drinking out of the forgotten table drinks  :0.1779</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: oh <text style=color:blue><i>[dear]</i></text> . were you drinking out of <text style=color:blue><i>[the]</i></text> <text style=color:blue><i>[disregarded]</i></text> table drinks : 0.0</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: oh <text style=color:blue><i>[dear]</i></text> . were you drinking out of <text style=color:blue><i>[the]</i></text> <text style=color:blue><i>[absolutely]</i></text> loved table drinks : 0.7778</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: one of my friend called me and asked to meet with her at mid valley today...but i have no time *sigh* :0.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: one of my friend called me and asked to meet with her at mid valley today...but i have no time *sigh*  :0.25</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: this week is not going as i had hoped :0.3818\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: this week is not going as i had hoped  :0.3818</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: this week is not going as i <text style=color:blue><i>[had]</i></text> hoped : 0.3818</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: this week is not going as i <text style=color:blue><i>[had]</i></text> absolutely hoped : 0.4391</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: i hate when i have to call and wake people up :-0.5719\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: i hate when i have to call and wake people up  :-0.5719</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[completely]</i></text> hate when i have to call and wake people up : -0.6115</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[fuck]</i></text> when i have to call and wake people up : -0.5423</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: just going to cry myself to sleep after watching marley and me.  :-0.4767\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: just going to cry myself to sleep after watching marley and me.   :-0.4767</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: just going <text style=color:blue><i>[to]</i></text> <text style=color:blue><i>[completely]</i></text> weep myself to sleep after watching marley and me . : -0.6115</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: just going <text style=color:blue><i>[to]</i></text> <text style=color:blue><i>[scream]</i></text> myself to sleep after watching marley and me . : -0.4019</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: im sad now  miss.lilly:-0.4767\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: im sad now  miss.lilly :-0.4767</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: im <text style=color:blue><i>[sick]</i></text> now miss.lilly : -0.5106</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: im <text style=color:blue><i>[sorry]</i></text> now miss.lilly : -0.0772</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: ooooh.... lol  that leslie.... and ok i will not do it again so leslie will not  get mad again :0.7669\n",
      "\n",
      "--- More options (total: 5184) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: ooooh.... lol  that leslie.... and ok i will not do it again so leslie will not  get mad again  :0.7669</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: ooooh ... <text style=color:blue><i>[.]</i></text> <text style=color:blue><i>[lmfao]</i></text> that leslie ... . and <text style=color:blue><i>[sorry]</i></text> i will not do it again so leslie will get <text style=color:blue><i>[<text style=color:blue><i>[mad]</i></text>]</i></text> again : 0.0</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: ooooh ... <text style=color:blue><i>[.]</i></text> <text style=color:blue><i>[absolutely]</i></text> lmfao that leslie ... . <text style=color:blue><i>[and]</i></text> ok i will not do it again so leslie will <text style=color:blue><i>[<text style=color:blue><i>[not]</i></text>]</i></text> get absolutely pissed again : 0.8617</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: meh... almost lover is the exception... this track gets me depressed every time. :0.0534\n",
      "\n",
      "--- More options (total: 200) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: meh... almost lover is the exception... this track gets me depressed every time.  :0.0534</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: meh ... almost <text style=color:blue><i>[friend]</i></text> is the exception ... this track gets <text style=color:blue><i>[me]</i></text> <text style=color:blue><i>[upset]</i></text> every time . : 0.0018</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: meh ... almost <text style=color:blue><i>[lover]</i></text> is the exception ... this track gets <text style=color:blue><i>[me]</i></text> <text style=color:blue><i>[gloomy]</i></text> every time . : 0.3832</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: some1 hacked my account on aim  now i have to make a new one:-0.4019\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: some1 hacked my account on aim  now i have to make a new one :-0.4019</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[some1]</i></text> <text style=color:blue><i>[completely]</i></text> hacked my account on aim now i have to make a new one : -0.4576</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[some1]</i></text> <text style=color:blue><i>[blocked]</i></text> my account on aim now i have to make a new one : -0.2732</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  i want to go to promote gear and groove but unfornately no ride there  i may b going to the one in anaheim in may though:-0.2144\n",
      "\n",
      "--- More options (total: 800) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i want to go to promote gear and groove but unfornately no ride there  i may b going to the one in anaheim in may though :-0.2144</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[completely]</i></text> lack to <text style=color:blue><i>[go]</i></text> <text style=color:blue><i>[to]</i></text> promote gear and groove but <text style=color:blue><i>[unfornately]</i></text> no ride there i may b going to the one in anaheim in may though : -0.4208</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[wish]</i></text> to go <text style=color:blue><i>[to]</i></text> <text style=color:blue><i>[absolutely]</i></text> promote gear and groove but <text style=color:blue><i>[unfornately]</i></text> no ride there i may b going to the one in anaheim in may though : -0.0009</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  awe i love you too!!!! 1 am here  i miss you:0.6973\n",
      "\n",
      "--- More options (total: 768) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  awe i love you too!!!! 1 am here  i miss you :0.6973</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: awe <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[dear]</i></text> you too ! ! ! ! 1 am here <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[completely]</i></text> lack you : 0.2903</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: awe <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[absolutely]</i></text> love you too ! ! ! ! 1 am <text style=color:blue><i>[here]</i></text> <text style=color:blue><i>[i]</i></text> love you : 0.9033</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  i cry my asian eyes to sleep at night :-0.4767\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i cry my asian eyes to sleep at night  :-0.4767</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[completely]</i></text> weep my asian eyes to sleep at night : -0.6115</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[i]</i></text> <text style=color:blue><i>[scream]</i></text> my asian eyes to sleep at night : -0.4019</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: ok i am sick and spent an hour sitting in the shower cause i was too sick to stand and held back the puke like a champ. bed now :-0.4939\n",
      "\n",
      "FOUND REPEATED WORD sick\n",
      "--- More options (total: 716800) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence: ok i am sick and spent an hour sitting in the shower cause i was too sick to stand and held back the puke like a champ. bed now  :-0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[sorry]</i></text> i <text style=color:blue><i>[am]</i></text> <text style=color:blue><i>[completely]</i></text> grim and spent an hour sitting in the shower cause i <text style=color:blue><i>[was]</i></text> <text style=color:blue><i>[too]</i></text> grim to stand and held <text style=color:blue><i>[back]</i></text> <text style=color:blue><i>[the]</i></text> <text style=color:blue><i>[puke]</i></text> like <text style=color:blue><i>[a]</i></text> championship . bed now : -0.8067</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[ok]</i></text> i <text style=color:blue><i>[am]</i></text> <text style=color:blue><i>[ugh]</i></text> and spent an hour sitting in the shower cause i was <text style=color:blue><i>[too]</i></text> <text style=color:blue><i>[absolutely]</i></text> crazy to stand and held <text style=color:blue><i>[back]</i></text> <text style=color:blue><i>[the]</i></text> <text style=color:blue><i>[absolutely]</i></text> puke <text style=color:blue><i>[like]</i></text> a champion . bed now : -0.0113</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  ill tell ya the story later  not a good day and ill be workin for like three more hours...:-0.6711\n",
      "\n",
      "FOUND REPEATED WORD ill\n",
      "--- More options (total: 6048) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  ill tell ya the story later  not a good day and ill be workin for like three more hours... :-0.6711</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[badly]</i></text> tell ya the story later not <text style=color:blue><i>[a]</i></text> <text style=color:blue><i>[completely]</i></text> great day <text style=color:blue><i>[and]</i></text> badly be workin <text style=color:blue><i>[for]</i></text> like three more hours ... : -0.8026</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[ill]</i></text> tell ya the story later a <text style=color:blue><i>[<text style=color:blue><i>[absolutely]</i></text>]</i></text> nice day <text style=color:blue><i>[and]</i></text> ill be workin <text style=color:blue><i>[for]</i></text> like three more hours ... : -0.0018</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  sorry! bed time came here gmt1   :-0.1511\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  sorry! bed time came here gmt1    :-0.1511</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[sorry]</i></text> ! bed time came here gmt1 : -0.1511</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet:  i do not either. its depressing. i do not think i even want to know about the kids in suitcases. :0.2411\n",
      "\n",
      "--- More options (total: 480) possible, but not printed ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>Actual Sentence:  i do not either. its depressing. i do not think i even want to know about the kids in suitcases.  :0.2411</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: i do not either . <text style=color:blue><i>[its]</i></text> <text style=color:blue><i>[disappointing]</i></text> . i do not think i <text style=color:blue><i>[even]</i></text> <text style=color:blue><i>[completely]</i></text> lack to know about the kids in suitcases . : 0.009</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: i do not either . <text style=color:blue><i>[its]</i></text> <text style=color:blue><i>[depressed]</i></text> . i do not think i <text style=color:blue><i>[even]</i></text> <text style=color:blue><i>[absolutely]</i></text> wish to know about the kids in suitcases . : 0.6903</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Tweet: bed. class 812. work 123. gym 35 or 6. then class 610. another day that is gonna fly by. i miss my girlfriend :-0.1531\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-28a9654feec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcounterOfTweets\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mnumOfTweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunThroughTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num of tweets done : {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumOfTweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-28a9654feec2>\u001b[0m in \u001b[0;36mrunThroughTweets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0}'th word's ({2}) options: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplacementDictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweetTokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msentenceObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnCombinationsOfStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenceObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0msentencesWithSentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentenceObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprintStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenceObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e7e3dbc2a1cb>\u001b[0m in \u001b[0;36mreturnCombinationsOfStrings\u001b[0;34m(sentenceObj)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortedKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mnextKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortedKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msortedKeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizedSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0msentenceChunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateSentenceChunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizedSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexToWordDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msortedKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e7e3dbc2a1cb>\u001b[0m in \u001b[0;36mgenerateSentenceChunks\u001b[0;34m(wholeSentence, keyToChange, nextKey, listOfMyAlternatives)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnewList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfMyAlternatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mnewList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwholeSentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeyToChange\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mgeneratedSentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def extractTwitterDataset():\n",
    "    df_tweets = pd.read_csv( pathToDatasets + 'cleanedTweets.csv', nrows=NUM_OF_TWEETS, skiprows =TWEET_START)\n",
    "    tweets = df_tweets.values\n",
    "    return tweets;\n",
    "\n",
    "def createDictionaryOfSentStrings(sentencesWithSentiment):\n",
    "    dict_sentimentToStringObjects = {}\n",
    "    for obj in sentencesWithSentiment:\n",
    "        sent = obj.getSentiment()\n",
    "        if(dict_sentimentToStringObjects.get(sent) == None):\n",
    "            dict_sentimentToStringObjects[sent] = [obj]\n",
    "        else:\n",
    "            (dict_sentimentToStringObjects[sent]).append(obj)\n",
    "\n",
    "    return dict_sentimentToStringObjects;\n",
    "\n",
    "def runThroughTweets():\n",
    "    tweets = extractTwitterDataset()\n",
    "    \n",
    "    counterOfTweets = 0;\n",
    "    for counter,tweet in enumerate(tweets):\n",
    "        counterOfTweets +=1;\n",
    "        tweet = tweet[0]\n",
    "        tweetTokens = cleanAndTokenizeText(tweet)\n",
    "        mainSentiment = senty.polarity_scores(tweet)['compound']\n",
    "        if(mainSentiment == 0):\n",
    "            continue\n",
    "        print(\"\\n\\n Tweet: {0}:{1}\\n\".format(tweet,mainSentiment))   \n",
    "        \n",
    "        sentenceObj = Sentence(tweet, mainSentiment)\n",
    "        sentenceObj = getAlternativeWords(sentenceObj)\n",
    "        sentenceObj = editBoosterWords(sentenceObj)\n",
    "        \n",
    "        replacementDictionary = sentenceObj.getDictOfIndexWords();\n",
    "        if(len(replacementDictionary) <= 0):        \n",
    "            print(\" -- No new Strings generated ---\\n\\n\")\n",
    "            continue\n",
    "\n",
    "        keysToChange = replacementDictionary.keys();\n",
    "        if(VERBOSE_PRINTING):\n",
    "            for key in keysToChange:\n",
    "                print(\"{0}'th word's ({2}) options: {1}\".format(key,replacementDictionary[key],tweetTokens[key]))\n",
    "\n",
    "        sentenceObj = returnCombinationsOfStrings(sentenceObj)\n",
    "        sentencesWithSentiment, sentenceObj = printStrings(sentenceObj)\n",
    "       \n",
    "        dict_sentimentToStringObjects = createDictionaryOfSentStrings(sentencesWithSentiment)\n",
    "        \n",
    "        sentiments = sorted(dict_sentimentToStringObjects.keys())\n",
    "        \n",
    "    return counterOfTweets;\n",
    "        \n",
    "numOfTweets = runThroughTweets()\n",
    "print(\"num of tweets done : {0}\".format(numOfTweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificWord = \"good\"\n",
    "def testOneWord(word=\"\"):\n",
    "    if(word==\"\"):\n",
    "        return\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "specificString = \"\"\n",
    "def specificString(textString=\"\"):\n",
    "    if(textString == \"\" or textString == None):\n",
    "        return\n",
    "    textString = dataClean(textString)\n",
    "    textTokens = cleanAndTokenizeText(textString)\n",
    "    mainSentiment = senty.polarity_scores(textString)['compound']\n",
    "    if(mainSentiment == 0):\n",
    "        print(\"{} \\n No sentiment found in sentence\".format(textString));\n",
    "        return;\n",
    "    print(\"\\n {0}:{1}\\n\".format(textString,mainSentiment))   \n",
    "    sentenceObj = Sentence(textString, mainSentiment)\n",
    "    sentenceObj = getAlternativeWords(sentenceObj)\n",
    "    sentenceObj = editBoosterWords(sentenceObj)\n",
    "    \n",
    "    \n",
    "    replacementDictionary = sentenceObj.getDictOfIndexWords();\n",
    "    if(len(replacementDictionary) <= 0):        \n",
    "        print(\" -- No new Strings generated ---\\n\\n\")\n",
    "        return\n",
    "    \n",
    "    keysToChange = replacementDictionary.keys();\n",
    "    if(VERBOSE_PRINTING):\n",
    "        for key in keysToChange:\n",
    "               print(\"{0}'th word's ({2}) options: {1}\".format(key,replacementDictionary[key],textTokens[key]))\n",
    "    \n",
    "    sentenceObj = returnCombinationsOfStrings(sentenceObj)\n",
    "    allPossibleSentences, sentenceObj = printStrings(sentenceObj)\n",
    "    \n",
    "print(\"Enter a string to use\")\n",
    "\n",
    "\n",
    "inputText = \"\"\n",
    "inputText = input()\n",
    "if(inputText == \"\"):\n",
    "    return\n",
    "elif(inputText == \"t\"):\n",
    "#     specificString(\"hot chocolate really angers me and it should sadden you too\")\n",
    "    specificString( \"the grind is inspirational and saddening at the same time. Do not want to stop you\"); # , cuz i like what u do \n",
    "#     specificString(\"the grind is inspirational and saddening at the same time. do not want you to stop cuz i like what u do!\")\n",
    "else:\n",
    "    specificString(inputText)\n",
    "# I really love hot chocolate, but I'm not good with hot coffee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
