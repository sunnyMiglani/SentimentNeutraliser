{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import string\n",
    "import nltk\n",
    "import sys\n",
    "import spacy\n",
    "    \n",
    "from IPython.display import HTML\n",
    "from nltk.corpus import wordnet \n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pathToDatasets = '../datasets/'\n",
    "pathToDataScripts = '../datasets/scripts/'\n",
    "filePath = '../datasets/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "sys.path.insert(0, pathToDataScripts)\n",
    "from cleanDataset import tokenize_words \n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading binaries and models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should I reload the model?\n",
      "yeet\n",
      "loading the model!\n",
      "Model Loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"Should I reload the model?\")\n",
    "tstString = input()\n",
    "if(\"no\" in tstString.lower() or \"n\" in tstString.lower()):\n",
    "    print(\" didnt reload model! \")\n",
    "else:\n",
    "    print(\"loading the model!\");\n",
    "    word_vectors = api.load(\"glove-wiki-gigaword-300\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('wordnet')\n",
    "    print(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables and Global Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "senty = SentimentIntensityAnalyzer()\n",
    "vocabulary = word_vectors.vocab;\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "NUMBER_OF_ALTERNATIVES = 5\n",
    "TWEET_START = 1\n",
    "NUM_OF_TWEETS = 10\n",
    "\n",
    "\n",
    "VERBOSE_PRINTING = True\n",
    "# VERBOSE_PRINTING = False\n",
    "\n",
    "# USE_SPACY = False\n",
    "USE_SPACY = True\n",
    "\n",
    "COLOR_PRINTING = True\n",
    "#COLOR_PRINTING = False\n",
    "\n",
    "# PRINT_NEUTRAL = True\n",
    "PRINT_NEUTRAL = False\n",
    "\n",
    "PRINT_ALL_STRINGS = True\n",
    "# PRINT_ALL_STRINGS = False\n",
    "\n",
    "SHOW_ALTS = 30\n",
    "\n",
    "punctuation = r\"\\\"#$%&'+-/;<=>?@[\\]*^_`{|}~\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported class file!\n"
     ]
    }
   ],
   "source": [
    "from SentenceClass import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStrings(sentenceObj):\n",
    "    \n",
    "    numberOfPrints = 0\n",
    "    newStrings = generateHTMLObjectsFromSentence(sentenceObj)\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "    listOfSentencesWithSentiments = []\n",
    "    bestSentiment = -sys.maxsize - 1\n",
    "    worstSentiment = sys.maxsize\n",
    "    \n",
    "    bestSentimentString = \"\";\n",
    "    worstSentimentString = \"\";\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ind, tSentence in enumerate(newStrings):\n",
    "            alteredTweet = tSentence.getSentence()\n",
    "            htmlText = tSentence.getHTML()\n",
    "            sentimentOfNewString = senty.polarity_scores(alteredTweet)['compound']\n",
    "            listOfSentencesWithSentiments.append(SentenceWithSentiment(alteredTweet, sentimentOfNewString, htmlText))\n",
    "            \n",
    "            if(sentimentOfNewString >= bestSentiment):\n",
    "                bestSentiment = sentimentOfNewString\n",
    "                bestSentimentString = htmlText;\n",
    "            elif(sentimentOfNewString < worstSentiment):\n",
    "                worstSentiment = sentimentOfNewString\n",
    "                worstSentimentString = htmlText;\n",
    "                \n",
    "            \n",
    "            if(sentimentOfNewString == mainSentiment or sentimentOfNewString == 0.0):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'black')\n",
    "                numberOfPrints+=1;\n",
    "            elif(sentimentOfNewString > mainSentiment):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'green')\n",
    "                numberOfPrints+=1;\n",
    "            elif(sentimentOfNewString < mainSentiment and sentimentOfNewString != 0.0):\n",
    "                if(PRINT_ALL_STRINGS and numberOfPrints <= SHOW_ALTS): displayText(\"{0}: {1}\".format(htmlText,sentimentOfNewString),'red')\n",
    "                numberOfPrints+=1;\n",
    "                \n",
    "    print(\"\\n\")\n",
    "    if(numberOfPrints > SHOW_ALTS): print(\"--- More options (total: {0}) possible, but not printed ---\".format(numberOfPrints));\n",
    "    if (worstSentimentString != \"\"): displayText(\"Worst Sentence: {0} : {1}\".format(worstSentimentString, worstSentiment), color='red')\n",
    "    if (bestSentimentString != \"\"): displayText(\"Best Sentence: {0} : {1}\".format(bestSentimentString, bestSentiment), color='green') \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    return listOfSentencesWithSentiments;\n",
    "\n",
    "def cstr(s, color='black', italics=False):\n",
    "    if(COLOR_PRINTING):\n",
    "        if(italics):\n",
    "            return cstr(\"<i>{0}</i>\".format(s), color);\n",
    "        return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "    else:\n",
    "        return \"{}\".format(s)\n",
    "\n",
    "def displayText(text, color='black'):\n",
    "    if(COLOR_PRINTING):\n",
    "        display(HTML(cstr(text, color)));\n",
    "        return\n",
    "    print(\"{}\".format(text));\n",
    "    \n",
    "    \n",
    "def cleanAndTokenizeText(text):\n",
    "    text = text.lower();\n",
    "    newString = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            newString += char\n",
    "    text = word_tokenize(newString)\n",
    "    return text;\n",
    "\n",
    "def getPOSTags(tweet):\n",
    "    if(USE_SPACY == False):\n",
    "        tags = nltk.pos_tag(tweet)\n",
    "        return tags;    \n",
    "    tweet = ' '.join(tweet)\n",
    "    doc = nlp(tweet)\n",
    "    tags = [(token.text, token.tag_) for token in doc] # since the format expected is [text,tag]\n",
    "    return tags\n",
    "\n",
    "def getAntonymsOfWords(word):\n",
    "    if(word not in vocabulary):\n",
    "        return []\n",
    "    setOfAntonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            anton = l.antonyms()\n",
    "            if(anton!=[]):\n",
    "                setOfAntonyms.add(anton[0].name())\n",
    "    if(len(setOfAntonyms) == 0):\n",
    "        if(VERBOSE_PRINTING): print(\"No antonyms found for word {0}\".format(word))\n",
    "    return list(setOfAntonyms)\n",
    "\n",
    "def returnReplacementsForWord(word):\n",
    "    \n",
    "    if(word not in vocabulary):\n",
    "        print(\" --- {0} not in vocabulary ---\".format(word))\n",
    "        return []\n",
    "    possibleReplacements = [word[0] for word in word_vectors.most_similar(word,topn=NUMBER_OF_ALTERNATIVES)]\n",
    "    \n",
    "    if(possibleReplacements == []):\n",
    "        print(\" --- No replacements for word {0} ---\".format(word))\n",
    "    antonyms = getAntonymsOfWords(word)\n",
    "    if(antonyms != []):\n",
    "        possibleReplacements.extend(antonyms)\n",
    "        if(VERBOSE_PRINTING): print(\"Some antonyms for word {0} are {1}\".format(word, antonyms[:3]))\n",
    "        return possibleReplacements\n",
    "    return possibleReplacements\n",
    "    \n",
    "def posApprovedReplacements(alternativeWords, userTokens, indexOfToken):\n",
    "    if(alternativeWords == []):\n",
    "        return []\n",
    "    tempTokens = userTokens[:]\n",
    "    POSTokens = getPOSTags(tempTokens)\n",
    "    validWords = []\n",
    "    \n",
    "    mainTag = POSTokens[indexOfToken][1]\n",
    "    mainWord = userTokens[indexOfToken]\n",
    "    \n",
    "    for ind,word in enumerate(alternativeWords):\n",
    "        tempTokens[indexOfToken] = word\n",
    "        posTags = getPOSTags(tempTokens)\n",
    "        newTag = (posTags[indexOfToken])[1]\n",
    "        \n",
    "        if(str(newTag) == str(mainTag)):\n",
    "            if(VERBOSE_PRINTING): print(\"Word {0}[{1}] replaced with {2}[{3}]\".format(mainWord, mainTag, word,newTag))\n",
    "            validWords.append(word)\n",
    "    if(validWords == [] and VERBOSE_PRINTING):\n",
    "        print(\"No POS words found for word {} with tag {}\".format(mainWord, mainTag));\n",
    "    return validWords\n",
    "    \n",
    "def generateHTMLObjectsFromSentence(sentenceObj):\n",
    "    \n",
    "    allSentences = sentenceObj.getFinalSentences()\n",
    "    indexToAlts = sentenceObj.indexToSetOfWords;\n",
    "    indexToChange = list(indexToAlts.keys());\n",
    "    \n",
    "    listOfSentenceObjs = []\n",
    "    for sentence in allSentences:\n",
    "        copySentence = cleanAndTokenizeText(sentence)\n",
    "        for index in indexToChange:\n",
    "            copySentence[index] = cstr(\"[{0}]\".format(copySentence[index]), \"blue\", italics=True);\n",
    "        listOfSentenceObjs.append(SentenceWithHTML(sentence, ' '.join(copySentence)));\n",
    "    \n",
    "    return listOfSentenceObjs\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Chunking and Appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_combine(mainList, myList):\n",
    "    '''\n",
    "    helper function for CombineSentenceChunks\n",
    "    '''\n",
    "    newList = []\n",
    "    for val in myList:\n",
    "        for mainVal in mainList:\n",
    "#             if(VERBOSE_PRINTING): print(\"Combining {0} with {1}\".format(' '.join(val), ' '.join(mainVal)));\n",
    "            newList.append(val + mainVal);\n",
    "    return newList;\n",
    "\n",
    "def combineSentenceChunks(wholeSentence, dictOfChunks):\n",
    "    '''\n",
    "        Uses the helper_combine function to generate all possible combinatios and permuations of the chunks\n",
    "        and any alternatives.\n",
    "        \n",
    "        The logic is to use the end of the sentence, apply each possible chunk from the previous key's chunks\n",
    "        to every possible chunk of this key's.\n",
    "        \n",
    "        The helper function is used to allow us to reuse the list of alreadyGeneratedChunks and constantly\n",
    "        append to them.\n",
    "        \n",
    "        To understand the logic better, take a look at this gist:\n",
    "        https://gist.github.com/sunnyMiglani/cf85407a9e6928237b1436cc2bc95fa4\n",
    "        \n",
    "    '''\n",
    "    reversedKeys = sorted(dictOfChunks.keys(), reverse=True)\n",
    "    completeSentences = [];\n",
    "    mainArr = dictOfChunks[reversedKeys[0]]\n",
    "    for ind in range(1, len(reversedKeys)):\n",
    "        key = reversedKeys[ind];\n",
    "        mainArr = helper_combine(mainArr, dictOfChunks[key]);\n",
    "        \n",
    "    return mainArr;\n",
    "        \n",
    "def generateSentenceChunks(wholeSentence, keyToChange, nextKey, listOfMyAlternatives):\n",
    "    '''\n",
    "        Generates sentence chunks by iterating through the list of alternatives\n",
    "        Chunking the sentence to start from current key to next key.\n",
    "        This means that the sentence always goes from key 'x' to key 'y'\n",
    "        \n",
    "        Example:\n",
    "        \"I really <hate> hot chocolate, but I <prefer> hot coffee\"\n",
    "        Calling generateSentenceChunks will create an example sentence:\n",
    "            - \"<altWordForHate> hot chocolate , but I \"\n",
    "        \n",
    "        Remember to append the first stretch of the string to the first key's chunk for proper use!\n",
    "    '''\n",
    "    newList = list(listOfMyAlternatives)\n",
    "    newList.append(wholeSentence[keyToChange]);\n",
    "    generatedSentences = []\n",
    "    for myAlt in newList:\n",
    "        newSentence = wholeSentence[:]\n",
    "        newSentence[keyToChange] = myAlt\n",
    "        if(VERBOSE_PRINTING): print(\"Generated : {}\".format(newSentence[keyToChange:nextKey]))\n",
    "        generatedSentences.append(newSentence[keyToChange:nextKey]);\n",
    "        \n",
    "    return generatedSentences\n",
    "    \n",
    "def returnCombinationsOfStrings(sentenceObj):\n",
    "    \n",
    "    indexToWordDict = sentenceObj.indexToSetOfWords;\n",
    "    originalSentence = sentenceObj.ogSentence;\n",
    "    tokenizedSentence = cleanAndTokenizeText(originalSentence)\n",
    "    reversedKeys = sorted(indexToWordDict.keys(), reverse=True)\n",
    "    dictAlternatives  = {}\n",
    "\n",
    "    sortedKeys = sorted(indexToWordDict.keys())\n",
    "    sentenceChunks = {}\n",
    "    htmlChunks = {}\n",
    "    \n",
    "    for ind in range(0,len(sortedKeys)):\n",
    "        key = sortedKeys[ind]\n",
    "        nextKey = sortedKeys[ind+1] if ind+1 < len(sortedKeys) else len(tokenizedSentence)\n",
    "        sentenceChunks[key] = generateSentenceChunks(tokenizedSentence, key, nextKey, indexToWordDict[key])\n",
    "\n",
    "    if(sortedKeys[0] != 0):\n",
    "        newList = []\n",
    "        for thislist in sentenceChunks[sortedKeys[0]]:\n",
    "            newList.append(tokenizedSentence[0:sortedKeys[0]] + thislist)\n",
    "        sentenceChunks[sortedKeys[0]] = newList;\n",
    "        \n",
    "    finalOptions = combineSentenceChunks(tokenizedSentence, sentenceChunks)\n",
    "    \n",
    "    finalSentences = []\n",
    "    for val in finalOptions:\n",
    "        sentence = ' '.join(val)\n",
    "        finalSentences.append(sentence)\n",
    "    \n",
    "    sentenceObj.resetFinalSentences()\n",
    "    sentenceObj.addFinalSentences(finalSentences)   \n",
    "    return sentenceObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAlternativeSentences(sentenceObj):\n",
    "    mainSentence = sentenceObj.ogSentence;\n",
    "    mainSentiment = sentenceObj.ogSentiment;\n",
    "\n",
    "    sentenceTokens = cleanAndTokenizeText(mainSentence)\n",
    "\n",
    "    for ind, word in enumerate(sentenceTokens):\n",
    "        alternativeSentenceWithHTML = []\n",
    "        copyOfTokens = sentenceTokens[:]\n",
    "        replacements = []\n",
    "        \n",
    "        score = senty.polarity_scores(word)['compound']\n",
    "        if(score != 0.0):\n",
    "            tempReplacements = returnReplacementsForWord(word) # get embedding based relations\n",
    "            if(tempReplacements == []):\n",
    "                print(\"No replacements found at all for word {0}\".format(word))\n",
    "                continue\n",
    "            replacements = posApprovedReplacements(tempReplacements[:], copyOfTokens[:], ind)\n",
    "            finalReplacements = []\n",
    "            if(VERBOSE_PRINTING): skippedWords = []\n",
    "            for word in replacements:\n",
    "                thisSentiment = senty.polarity_scores(word)['compound']\n",
    "                if(thisSentiment != 0.0):\n",
    "                    finalReplacements.append(word)\n",
    "                else:\n",
    "                    if(VERBOSE_PRINTING):\n",
    "#                         print(\"Sentiment of Skipped word {} is {}\".format(word, senty.polarity_scores(word)))\n",
    "                        skippedWords.append(word)\n",
    "            if(VERBOSE_PRINTING and len(skippedWords) > 0):\n",
    "                print(\"some skipped words: {0}\".format(skippedWords[:5]));\n",
    "            if(finalReplacements == []):\n",
    "                print(\" -- No POS approved words! -- for word {0}\\n some non-POS:{1}\".format(word, tempReplacements[:4]))\n",
    "                continue\n",
    "            sentenceObj.addAlternativesByIndex(ind, finalReplacements)\n",
    "    return sentenceObj\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " is upset that he can not update his facebook by texting it... and might cry as a result  school today also. blah!:-0.75\n",
      "\n",
      "No antonyms found for word upset\n",
      "Word upset[VBN] replaced with shocked[VBN]\n",
      "Some antonyms for word cry are ['laugh']\n",
      "Word cry[VB] replaced with scream[VB]\n",
      "Word cry[VB] replaced with shout[VB]\n",
      "Word cry[VB] replaced with laugh[VB]\n",
      "some skipped words: ['shout']\n",
      "No antonyms found for word blah\n",
      "Word blah[UH] replaced with goy[UH]\n",
      "Word blah[UH] replaced with vich[UH]\n",
      "some skipped words: ['goy', 'vich']\n",
      " -- No POS approved words! -- for word vich\n",
      " some non-POS:['goy', 'stuh', 'blagojevich', 'vich']\n",
      "1'th word's (upset) options: {'shocked'}\n",
      "15'th word's (cry) options: {'scream', 'laugh'}\n",
      "Generated : ['shocked', 'that', 'he', 'can', 'not', 'update', 'his', 'facebook', 'by', 'texting', 'it', '...', 'and', 'might']\n",
      "Generated : ['upset', 'that', 'he', 'can', 'not', 'update', 'his', 'facebook', 'by', 'texting', 'it', '...', 'and', 'might']\n",
      "Generated : ['scream', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!']\n",
      "Generated : ['laugh', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!']\n",
      "Generated : ['cry', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>is <text style=color:blue><i>[shocked]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[scream]</i></text> as a result school today also . blah !: -0.69</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>is <text style=color:blue><i>[shocked]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[laugh]</i></text> as a result school today also . blah !: 0.2942</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>is <text style=color:blue><i>[shocked]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[cry]</i></text> as a result school today also . blah !: -0.7263</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>is <text style=color:blue><i>[upset]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[scream]</i></text> as a result school today also . blah !: -0.7177</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>is <text style=color:blue><i>[upset]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[laugh]</i></text> as a result school today also . blah !: 0.2244</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>is <text style=color:blue><i>[upset]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[cry]</i></text> as a result school today also . blah !: -0.75</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: is <text style=color:blue><i>[upset]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[cry]</i></text> as a result school today also . blah ! : -0.75</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: is <text style=color:blue><i>[shocked]</i></text> that he can not update his facebook by texting it ... and might <text style=color:blue><i>[laugh]</i></text> as a result school today also . blah ! : 0.2942</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  i dived many times for the ball. managed to save 50  the rest go out of bounds:0.4939\n",
      "\n",
      "No antonyms found for word save\n",
      "Word save[VB] replaced with help[VB]\n",
      "Word save[VB] replaced with effort[VB]\n",
      "some skipped words: ['effort']\n",
      "10'th word's (save) options: {'help'}\n",
      "Generated : ['help', '50', 'the', 'rest', 'go', 'out', 'of', 'bounds']\n",
      "Generated : ['save', '50', 'the', 'rest', 'go', 'out', 'of', 'bounds']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>i dived many times for the ball . managed to <text style=color:blue><i>[help]</i></text> 50 the rest go out of bounds: 0.4019</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>i dived many times for the ball . managed to <text style=color:blue><i>[save]</i></text> 50 the rest go out of bounds: 0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: i dived many times for the ball . managed to <text style=color:blue><i>[save]</i></text> 50 the rest go out of bounds : 0.4939</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " my whole body feels itchy and like its on fire :-0.25\n",
      "\n",
      "No antonyms found for word itchy\n",
      "Word itchy[JJ] replaced with scratchy[JJ]\n",
      "Word itchy[JJ] replaced with runny[JJ]\n",
      "some skipped words: ['scratchy', 'runny']\n",
      " -- No POS approved words! -- for word runny\n",
      " some non-POS:['scratchy', 'itching', 'blisters', 'rashes']\n",
      "Some antonyms for word like are ['unlike', 'dislike', 'unalike']\n",
      "Word like[IN] replaced with unlike[IN]\n",
      "some skipped words: ['unlike']\n",
      " -- No POS approved words! -- for word unlike\n",
      " some non-POS:['such', 'even', 'you', '?']\n",
      "Some antonyms for word fire are ['hire']\n",
      "Word fire[NN] replaced with blaze[NN]\n",
      "Word fire[NN] replaced with firing[NN]\n",
      "Word fire[NN] replaced with hire[NN]\n",
      "some skipped words: ['blaze', 'hire']\n",
      "9'th word's (fire) options: {'firing'}\n",
      "Generated : ['firing']\n",
      "Generated : ['fire']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>my whole body feels itchy and like its on <text style=color:blue><i>[firing]</i></text>: -0.25</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>my whole body feels itchy and like its on <text style=color:blue><i>[fire]</i></text>: -0.25</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: my whole body feels itchy and like its on <text style=color:blue><i>[fire]</i></text> : -0.25</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  no it is not behaving at all. i am mad. why am i here because i can not see you all over there. :-0.6597\n",
      "\n",
      "Some antonyms for word no are ['yes', 'all']\n",
      "Word no[UH] replaced with yes[UH]\n",
      "No antonyms found for word mad\n",
      "Word mad[JJ] replaced with bovine[JJ]\n",
      "Word mad[JJ] replaced with bse[JJ]\n",
      "Word mad[JJ] replaced with spongiform[JJ]\n",
      "Word mad[JJ] replaced with crazy[JJ]\n",
      "some skipped words: ['bovine', 'bse', 'spongiform']\n",
      "0'th word's (no) options: {'yes'}\n",
      "10'th word's (mad) options: {'crazy'}\n",
      "Generated : ['yes', 'it', 'is', 'not', 'behaving', 'at', 'all', '.', 'i', 'am']\n",
      "Generated : ['no', 'it', 'is', 'not', 'behaving', 'at', 'all', '.', 'i', 'am']\n",
      "Generated : ['crazy', '.', 'why', 'am', 'i', 'here', 'because', 'i', 'can', 'not', 'see', 'you', 'all', 'over', 'there', '.']\n",
      "Generated : ['mad', '.', 'why', 'am', 'i', 'here', 'because', 'i', 'can', 'not', 'see', 'you', 'all', 'over', 'there', '.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green><text style=color:blue><i>[yes]</i></text> it is not behaving at all . i am <text style=color:blue><i>[crazy]</i></text> . why am i here because i can not see you all over there .: 0.0772</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green><text style=color:blue><i>[yes]</i></text> it is not behaving at all . i am <text style=color:blue><i>[mad]</i></text> . why am i here because i can not see you all over there .: -0.128</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green><text style=color:blue><i>[no]</i></text> it is not behaving at all . i am <text style=color:blue><i>[crazy]</i></text> . why am i here because i can not see you all over there .: -0.5574</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black><text style=color:blue><i>[no]</i></text> it is not behaving at all . i am <text style=color:blue><i>[mad]</i></text> . why am i here because i can not see you all over there .: -0.6597</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: <text style=color:blue><i>[no]</i></text> it is not behaving at all . i am <text style=color:blue><i>[mad]</i></text> . why am i here because i can not see you all over there . : -0.6597</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: <text style=color:blue><i>[yes]</i></text> it is not behaving at all . i am <text style=color:blue><i>[crazy]</i></text> . why am i here because i can not see you all over there . : 0.0772</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " need a hug :0.4767\n",
      "\n",
      "No antonyms found for word hug\n",
      "Word hug[NN] replaced with goodbye[NN]\n",
      "Word hug[NN] replaced with kiss[NN]\n",
      "some skipped words: ['goodbye']\n",
      "2'th word's (hug) options: {'kiss'}\n",
      "Generated : ['kiss']\n",
      "Generated : ['hug']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>need a <text style=color:blue><i>[kiss]</i></text>: 0.4215</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>need a <text style=color:blue><i>[hug]</i></text>: 0.4767</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: need a <text style=color:blue><i>[hug]</i></text> : 0.4767</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  hey  long time no see! yes.. rains a bit only a bit  lol  i am fine thanks  how is you :0.68\n",
      "\n",
      "Some antonyms for word no are ['yes', 'all']\n",
      "Word no[UH] replaced with yes[UH]\n",
      "No antonyms found for word lol\n",
      "Word lol[NN] replaced with choua[NN]\n",
      "Word lol[NN] replaced with coxhill[NN]\n",
      "Word lol[NN] replaced with creme[NN]\n",
      "Word lol[NN] replaced with 10cc[NN]\n",
      "Word lol[NN] replaced with godley[NN]\n",
      "some skipped words: ['choua', 'coxhill', 'creme', '10cc', 'godley']\n",
      " -- No POS approved words! -- for word godley\n",
      " some non-POS:['choua', 'coxhill', 'creme', '10cc']\n",
      "Some antonyms for word fine are ['coarse']\n",
      "Word fine[VBP] replaced with fines[VBP]\n",
      "Word fine[VBP] replaced with art[VBP]\n",
      "Word fine[VBP] replaced with well[VBP]\n",
      "Word fine[VBP] replaced with arts[VBP]\n",
      "Word fine[VBP] replaced with 'll[VBP]\n",
      "Word fine[VBP] replaced with coarse[VBP]\n",
      "some skipped words: ['fines', 'art', 'arts', \"'ll\", 'coarse']\n",
      "No antonyms found for word thanks\n",
      "Word thanks[JJ] replaced with despite[JJ]\n",
      "Word thanks[JJ] replaced with success[JJ]\n",
      "Word thanks[JJ] replaced with good[JJ]\n",
      "some skipped words: ['despite']\n",
      "3'th word's (no) options: {'yes'}\n",
      "16'th word's (fine) options: {'well'}\n",
      "17'th word's (thanks) options: {'good', 'success'}\n",
      "Generated : ['yes', 'see', '!', 'yes..', 'rains', 'a', 'bit', 'only', 'a', 'bit', 'lol', 'i', 'am']\n",
      "Generated : ['no', 'see', '!', 'yes..', 'rains', 'a', 'bit', 'only', 'a', 'bit', 'lol', 'i', 'am']\n",
      "Generated : ['well']\n",
      "Generated : ['fine']\n",
      "Generated : ['good', 'how', 'is', 'you']\n",
      "Generated : ['success', 'how', 'is', 'you']\n",
      "Generated : ['thanks', 'how', 'is', 'you']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[good]</i></text> how is you: 0.8687</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[success]</i></text> how is you: 0.8908</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[thanks]</i></text> how is you: 0.8687</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[good]</i></text> how is you: 0.8588</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[success]</i></text> how is you: 0.8832</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[thanks]</i></text> how is you: 0.8588</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[good]</i></text> how is you: 0.7088</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[success]</i></text> how is you: 0.7712</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[thanks]</i></text> how is you: 0.7088</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[good]</i></text> how is you: 0.68</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[success]</i></text> how is you: 0.75</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[thanks]</i></text> how is you: 0.68</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>Worst Sentence: hey long time <text style=color:blue><i>[no]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[fine]</i></text> <text style=color:blue><i>[good]</i></text> how is you : 0.68</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: hey long time <text style=color:blue><i>[yes]</i></text> see ! yes.. rains a bit only a bit lol i am <text style=color:blue><i>[well]</i></text> <text style=color:blue><i>[success]</i></text> how is you : 0.8908</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num of tweets done : 10\n"
     ]
    }
   ],
   "source": [
    "def extractTwitterDataset():\n",
    "    df_tweets = pd.read_csv( pathToDatasets + 'cleanedTweets.csv', nrows=NUM_OF_TWEETS, skiprows =TWEET_START)\n",
    "    tweets = df_tweets.values\n",
    "    return tweets;\n",
    "\n",
    "\n",
    "def runThroughTweets():\n",
    "    tweets = extractTwitterDataset()\n",
    "    \n",
    "    counterOfTweets = 0;\n",
    "    for counter,tweet in enumerate(tweets):\n",
    "        counterOfTweets +=1;\n",
    "        tweet = tweet[0]\n",
    "        tweetTokens = cleanAndTokenizeText(tweet)\n",
    "        mainSentiment = senty.polarity_scores(tweet)['compound']\n",
    "        if(mainSentiment == 0):\n",
    "            continue\n",
    "        print(\"\\n {0}:{1}\\n\".format(tweet,mainSentiment))   \n",
    "        sentenceObj = Sentence(tweet, mainSentiment)\n",
    "        sentenceObj = getAlternativeSentences(sentenceObj)\n",
    "        replacementDictionary = sentenceObj.getDictOfIndexWords();\n",
    "        if(len(replacementDictionary) <= 0):        \n",
    "            print(\" -- No new Strings generated ---\\n\\n\")\n",
    "            continue\n",
    "\n",
    "        keysToChange = replacementDictionary.keys();\n",
    "        for key in keysToChange:\n",
    "            if(VERBOSE_PRINTING):print(\"{0}'th word's ({2}) options: {1}\".format(key,replacementDictionary[key],tweetTokens[key]))\n",
    "\n",
    "        sentenceObj = returnCombinationsOfStrings(sentenceObj)\n",
    "        allPossible = printStrings(sentenceObj)\n",
    "    return counterOfTweets;\n",
    "        \n",
    "numOfTweets = runThroughTweets()\n",
    "print(\"num of tweets done : {0}\".format(numOfTweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificWord = \"good\"\n",
    "def testOneWord(word=\"\"):\n",
    "    if(word==\"\"):\n",
    "        return\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I am the BEST builder, just look at what I've built:0.7125\n",
      "\n",
      "Some antonyms for word best are ['badly', 'ill', 'evil']\n",
      "Word best[JJS] replaced with worst[JJS]\n",
      "3'th word's options: {'worst'}\n",
      "Generated : ['worst', 'builder', ',', 'just', 'look', 'at', 'what', 'ive', 'built']\n",
      "Generated : ['best', 'builder', ',', 'just', 'look', 'at', 'what', 'ive', 'built']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>i am the <text style=color:blue><i>[worst]</i></text> builder , just look at what ive built: -0.6249</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>i am the <text style=color:blue><i>[best]</i></text> builder , just look at what ive built: 0.6369</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:green>Best Sentence: i am the <text style=color:blue><i>[best]</i></text> builder , just look at what ive built : 0.6369</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " I am least racist person there is:0.4973\n",
      "\n",
      "No antonyms found for word racist\n",
      "Word racist[JJ] replaced with homophobic[JJ]\n",
      "Word racist[JJ] replaced with sexist[JJ]\n",
      "Word racist[JJ] replaced with semitic[JJ]\n",
      "Word racist[JJ] replaced with xenophobic[JJ]\n",
      "some skipped words: ['homophobic', 'sexist', 'semitic', 'xenophobic']\n",
      " -- No POS approved words! -- for word xenophobic\n",
      " some non-POS:['homophobic', 'sexist', 'semitic', 'xenophobic']\n",
      " -- No new Strings generated ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "specificString = \"\"\n",
    "def specificString(textString=\"\"):\n",
    "    if(textString == \"\" or textString == None):\n",
    "        return\n",
    "    mainSentiment = senty.polarity_scores(textString)['compound']\n",
    "    if(mainSentiment == 0):\n",
    "        print(\"{} \\n No sentiment found in sentence\".format(textString));\n",
    "        return;\n",
    "    print(\"\\n {0}:{1}\\n\".format(textString,mainSentiment))   \n",
    "    sentenceObj = Sentence(textString, mainSentiment)\n",
    "    sentenceObj = getAlternativeSentences(sentenceObj)\n",
    "    replacementDictionary = sentenceObj.getDictOfIndexWords();\n",
    "    if(len(replacementDictionary) <= 0):        \n",
    "        print(\" -- No new Strings generated ---\\n\\n\")\n",
    "        return\n",
    "    \n",
    "    keysToChange = replacementDictionary.keys();\n",
    "    for key in keysToChange:\n",
    "        print(\"{0}'th word's options: {1}\".format(key,replacementDictionary[key]))\n",
    "        \n",
    "    sentenceObj = returnCombinationsOfStrings(sentenceObj)\n",
    "    allPossibleSentences = printStrings(sentenceObj)\n",
    "    \n",
    "\n",
    "specificString(\"I am the BEST builder, just look at what I've built\")\n",
    "specificString(\"I am least racist person there is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
